- title: "SOLE: towards descriptive and interactive publications"
  Authors: "Tanu Malik, Quan Pham, Ian T Foster, F Leisch, and RD Peng"
  Journal: "Implementing reproducible research"
  Publisher: "CRC Press"
  Description: "2 Dummy title corroborate descriptions through indirect means, such as by building companion websites that share data and software packages, these external websites continue to remain disconnected from the content within the paper, making it difficult to verify claims and reproduce results. There is an critical need for systems that minimize this disconnect. We describe Science Object Linking and Embedding (SOLE), a framework for creating descriptive and interactive publications by linking them with associated science objects, such as source codes, datasets, annotations, workflows, re-playable packages, and virtual machine images. SOLE provides a suite of tools that assist the author to create and host science objects that can then be linked with research papers for the purpose of assessment, repeatability, and verification of research. The framework also creates a linkable representation of the science object with the publication and manages a bibliography-like specification of science objects. In this chapter, we introduce SOLE, and describe its use for augmenting the content of computation-based scientific publications. We present examples from climate science, chemistry, biology, and computer science."
  bibAuthors: "Malik, Tanu and Pham, Quan and Foster, Ian T F and Leisch, F and Peng, RD"
  Year: 2014
  Date: 20140000
  id: "publication-0"

- title: "Estimating query result sizes for proxy caching in scientific database federations"
  Authors: "Tanu Malik, Randal Burns, Nitesh V Chawla, and Alex Szalay"
  Conference: "SC'06: Proceedings of the 2006 ACM/IEEE Conference on Supercomputing"
  Pages: "36-36"
  Publisher: "IEEE"
  Description: "In a proxy cache for federations of scientific databases it is important to estimate the size of a query before making a caching decision. With accurate estimates, near-optimal cache performance can be obtained. On the other extreme, inaccurate estimates can render the cache totally ineffective. We present classification and regression over templates (CAROT), a general method for estimating query result sizes, which is suited to the resource-limited environment of proxy caches and the distributed nature of database federations. CAROT estimates query result sizes by learning the distribution of query results, not by examining or sampling data, but from observing workload. We have integrated CAROT into the proxy cache of the National Virtual Observatory (NVO) federation of astronomy databases. Experiments conducted in the NVO show that CAROT dramatically outperforms conventional estimation techniques and …"
  bibAuthors: "Malik, Tanu and Burns, Randal and Chawla, Nitesh V C and Szalay, Alex"
  Year: 2006
  Month: "November"
  Day: 11
  Date: 20061111
  id: "publication-1"

- title: "Addressing data access needs of the long-tail distribution of geoscientists"
  Authors: "Tanu Malik, and Ian Foster"
  Conference: "2012 IEEE International Geoscience and Remote Sensing Symposium"
  Pages: "5348-5351"
  Publisher: "IEEE"
  Description: "Data and computation are fundamental to advances in geoscience research and discovery. However, geoscientists currently spend too much time looking for the “right” data, subsequently accessing these data, and then transforming them into a form suitable for analysis. This data management overhead affects a scientists' competitive advantage in making useful contributions. Several cyber-infrastructure (CI) efforts are being undertaken to improve the data management needs of the long-tail geoscientists. In this paper, we highlight characteristics of CI solutions that will form the basis for the successful and widely adopted solutions."
  bibAuthors: "Malik, Tanu and Foster, Ian"
  Year: 2012
  Month: "July"
  Day: 22
  Date: 20120722
  id: "publication-2"

- title: "Leveraging Scientific Cyberinfrastructures to Achieve Computational Hydrologic Model Reproducibility"
  Authors: "JM Sadler, BT Essawy, JL Goodall, D Voce, Y CHOI, MM Morsy, Z Yuan, and T Malik"
  Journal: "AGU Fall Meeting Abstracts"
  Volume: "2018"
  Pages: "C13J-1252"
  Description: "Achieving reproducibility of computational models and workflows is an important challenge that calls for open and reusable code and data, well-documented workflows, and controlled environments that allow others to verify published findings. HydroShare (http://www. hydroshare. org) and GeoTrust (http://geotrusthub. org/), two new cyberinfrastructure tools under active development, have the potential to address this challenge in the field of computational hydrology. HydroShare is a web-based system for sharing hydrologic data and models as digital resources. HydroShare allows hydrologists to upload model input data resources, add detailed hydrologic-specific metadata to these resources, and interact with the data directly within HydroShare for collaborative modeling using tools like JupyterHub. GeoTrust provides tools for scientists to efficiently reproduce, track and share geoscience applications by building …"
  bibAuthors: "Sadler, JM and Essawy, BT and Goodall, JL and Voce, D and CHOI, Y and Morsy, MM and Yuan, Z and Malik, T"
  Year: 2018
  Month: "December"
  Date: 20181200
  id: "publication-3"

- title: "Using provenance for generating automatic citations"
  Authors: "Dai Hai Ton That, Andrew Youngdahl, Alexander Rasin, and Tanu Malik"
  Book: "Proceedings of the 10th USENIX Conference on Theory and Practice of Provenance"
  Pages: "1-1"
  Description: "When computational experiments include only datasets, they could be shared through the Uniform Resource Identifiers (URIs) or Digital Object Identifiers (DOIs) which point to these resources. However, experiments seldom include only datasets, but most often also include software, execution results, provenance, and other associated documentation. The Research Object has recently emerged as a comprehensive and systematic method for aggregation and identification of diverse elements of computational experiments. While an entire Research Object may be citable using a URI or a DOI, it is often desirable to cite specific sub-components of a research object to help identify, authorize, date, and retrieve the published sub-components of these objects. In this paper, we present an approach to automatically generate citations for sub-components of research objects by using the object's recorded provenance …"
  bibAuthors: "That, Dai H T T and Youngdahl, Andrew and Rasin, Alexander and Malik, Tanu"
  Year: 2018
  Month: "July"
  Day: 11
  Date: 20180711
  id: "publication-4"

- title: "Benchmarking cloud-based tagging services"
  Authors: "Tanu Malik, Kyle Chard, and Ian Foster"
  Conference: "2014 IEEE 30th International Conference on Data Engineering Workshops"
  Pages: "231-238"
  Publisher: "IEEE"
  Description: "Tagging services have emerged as a useful and popular way to organize data resources. Despite popular interest, an efficient implementation of tagging services is a challenge since highly dynamic schemas and sparse, heterogeneous attributes must be supported within a shared, openly writable database. NoSQL databases support dynamic schemas and sparse data but lack efficient native support for joins that are inherent to query and search functionality in tagging services. Relational databases provide sufficient support for joins, but offer a multitude of options to manifest dynamic schemas and tune sparse data models, making evaluation of a tagging service time consuming and painful. In this case-study paper, we describe a benchmark for tagging services, and propose benchmarking modules that can be used to evaluate the suitability of a database for workloads generated from tagging services. We have …"
  bibAuthors: "Malik, Tanu and Chard, Kyle and Foster, Ian"
  Year: 2014
  Month: "March"
  Day: 31
  Date: 20140331
  id: "publication-5"

- title: "On lowering merge costs of an lsm tree"
  Authors: "Dai Hai Ton That, Mohammadsaleh Gharehdaghi, Alexander Rasin, and Tanu Malik"
  Book: "33rd International Conference on Scientific and Statistical Database Management"
  Pages: "253-258"
  Description: "In column stores, which ingest large amounts of data into multiple column groups, query performance deteriorates. Commercial column stores use log-structured merge (LSM) tree on projections to ingest data rapidly. LSM tree improves ingestion performance, but for column stores the sort-merge maintenance phase in an LSM tree is I/O-intensive, which slows concurrent queries and reduces overall throughput. In this paper, we present a simple heuristic approach to reduce the sorting and merging cost that arise when data is ingested in column stores. We demonstrate how a Min-Max heuristic can construct buckets and identify the level of sortedness in each range of data. Filled and relatively-sorted buckets are written out to disk; unfilled buckets are retained to achieve a better level of sortedness, thus avoiding the expensive sort-merge phase. We compare our Min-Max approach with LSM tree and production …"
  bibAuthors: "That, Dai H T T and Gharehdaghi, Mohammadsaleh and Rasin, Alexander and Malik, Tanu"
  Year: 2021
  Month: "July"
  Day: 6
  Date: 20210706
  id: "publication-6"

- title: "Auditing and maintaining provenance in software packages"
  Authors: "Tanu Malik, Tanu Malik Malik, Ian Foster, Quan Pham Pham, Quan Pham, and Ian Foster Foster"
  Volume: "2015"
  Description: "Science projects are increasingly investing in computational reproducibility. Constructing software pipelines to demonstrate reproducibility is also becoming increasingly common. To aid the process of constructing pipelines, science project members often adopt reproducible methods and tools. One such tool is CDE, which is a software packaging tool that encapsulates source code, datasets and environments. However, CDE does not include information about origins of dependencies. Consequently when multiple CDE packages are combined and merged to create a software pipeline, several issues arise requiring an author to manually verify compatibility of distributions, environment variables, software dependencies and compiler options. In this work, we propose software provenance to be included as part of CDE so that resulting provenance-included CDE packages can be easily used for creating software …"
  bibAuthors: "Malik, Tanu and Malik, Tanu M M and Foster, Ian and Pham, Quan P P and Pham, Quan and Foster, Ian F F"
  Year: 2015
  Month: "March"
  Day: 20
  Date: 20150320
  id: "publication-7"

- title: "Rule-based classification systems for informatics"
  Authors: "Balachander Krishnamurthy, Tanu Malik, Stephen Stamatis, Venkat Venkatasubramanian, and J Caruthers"
  Conference: "2008 IEEE Fourth International Conference on eScience"
  Pages: "420-421"
  Publisher: "IEEE"
  Description: "Classification of data is an important step in the knowledge evolution of sciences. Traditionally, in sciences, classification of data was performed by human experts. Human knowledge can recognize unique functional properties that are necessary and sufficient to place complex structures and phenomena into a particular class or group. However, with the growth in scientific data and rapid changes in knowledge, it is no longer feasible for humans to classify objects. Automation of the classification process is necessary to cope with the growing amount of data. Otherwise, classification will become the rate-limiting step for scientific data analysis.In this paper, we address the needs of such automation in the SciAEther project and develop ChES, a fast and reproducible framework for classifying molecules in chemical data. Our framework captures human understanding through an ontology and the diversity in classification …"
  bibAuthors: "Krishnamurthy, Balachander and Malik, Tanu and Stamatis, Stephen and Venkatasubramanian, Venkat and Caruthers, J"
  Year: 2008
  Month: "December"
  Day: 7
  Date: 20081207
  id: "publication-8"

- title: "The SDSS SkyServer–Public Access to the Sloan Digital Sky Server Data"
  Authors: "Jim Gray, Alexander Szalay, Ani Thakar, Peter Z Zunszt, Tanu Malik, Jordan Raddick, and Christopher Stoughton"
  Description: "The SkyServer provides Internet access to the public Sloan Digital Sky Survey (SDSS) data for both astronomers and for science education. This paper describes the SkyServer goals and architecture. It also describes our experience operating the SkyServer on the Internet. The SDSS data is public and well-documented so it makes a good test platform for research on database algorithms and performance."
  bibAuthors: "Gray, Jim and Szalay, Alexander and Thakar, Ani and Zunszt, Peter Z Z and Malik, Tanu and Raddick, Jordan and Stoughton, Christopher"
  Year: 2001
  Month: "November"
  Day: 1
  Date: 20011101
  id: "publication-9"

- title: "Jaws: Job-aware workload scheduling for the exploration of turbulence simulations"
  Authors: "Xiaodan Wang, Eric Perlman, Randal Burns, Tanu Malik, Tamas Budavári, Charles Meneveau, and Alexander Szalay"
  Conference: "SC'10: Proceedings of the 2010 ACM/IEEE International Conference for High Performance Computing, Networking, Storage and Analysis"
  Pages: "1-11"
  Publisher: "IEEE"
  Description: "We present JAWS, a job-aware, data-driven batch scheduler that improves query throughput for data-intensive scientific database clusters. As datasets reach petabyte-scale, workloads that scan through vast amounts of data to extract features are gaining importance in the sciences. However, acute performance bottlenecks result when multiple queries execute simultaneously and compete for I/O resources. Our solution, JAWS, divides queries into I/O-friendly sub-queries for scheduling. It then identifies overlapping data requirements within the workload and executes sub-queries in batches to maximize data sharing and reduce redundant I/O. JAWS extends our previous work by supporting workflows in which queries exhibit data dependencies, exploiting workload knowledge to coordinate caching decisions, and combating starvation through adaptive and incremental trade-offs between query throughput and …"
  bibAuthors: "Wang, Xiaodan and Perlman, Eric and Burns, Randal and Malik, Tanu and Budavári, Tamas and Meneveau, Charles and Szalay, Alexander"
  Year: 2010
  Month: "November"
  Day: 13
  Date: 20101113
  id: "publication-10"

- title: "Tracking and sketching distributed data provenance"
  Authors: "Tanu Malik, Ligia Nistor, and Ashish Gehani"
  Conference: "2010 IEEE Sixth International Conference on e-Science"
  Pages: "190-197"
  Publisher: "IEEE"
  Description: "Current provenance collection systems typically gather metadata on remote hosts and submit it to a central server. In contrast, several data-intensive scientific applications require a decentralized architecture in which each host maintains an authoritative local repository of the provenance metadata gathered on that host. The latter approach allows the system to handle the large amounts of metadata generated when auditing occurs at fine granularity, and allows users to retain control over their provenance records. The decentralized architecture, however, increases the complexity of auditing, tracking, and querying distributed provenance. We describe a system for capturing data provenance in distributed applications, and the use of provenance sketches to optimize subsequent data provenance queries. Experiments with data gathered from distributed workflow applications demonstrate the feasibility of a …"
  bibAuthors: "Malik, Tanu and Nistor, Ligia and Gehani, Ashish"
  Year: 2010
  Month: "December"
  Day: 7
  Date: 20101207
  id: "publication-11"

- title: "A Portable Approach for Repeatability Testing"
  Authors: "Quan Pham, Tanu Malik, and Ian Foster"
  Description: "Provenance-To-Use (PTU) is a tool from SOLE Framework that minimizes computation time during repeatability testing of computation-based experiments. PTU allows authors to assemble code, data, environment, and provenance of an initial reference execution into a single package that can be distributed to testers. The resulting package allows testers to view the provenance graph and specify, at a process and file level, nodes of the graph that they want for a partial deterministic replay-based, for example, on their compute, memory and I/O utilization as measured during the reference execution. Using the provenance trace, PTU guarantees that events are processed in the same order using the same data from one execution to the next. We show the efficiency of PTU for conducting repeatability testing of workflow-based scientific programs outweighs the overhead incurred during the reference executions."
  bibAuthors: "Pham, Quan and Malik, Tanu and Foster, Ian"
  id: "publication-12"

- title: "GCASR’14"
  Authors: "Quan Pham, Tanu Malik, and Ian Foster"
  Description: "Objective
          

           This paper describes an extension to PTU [1], a provenance tracking and replay tool. Our extension implements a provenance capture framework for network data in distributed experiments with minimal setup, while provides an execution replay framework to re-execute network processes offline.
          

           Provenance Model As the standard Open Provenance Model (OPM) does not specify how network provenance is modeled, we propose to support network-data-to-process dependency using OPM data artifact. We define socket node as a specific data artifact that stores metadata about a network TCP/IP socket (IP addresses, ports, and connection time) and actual data content to support network replay."
  bibAuthors: "Pham, Quan and Malik, Tanu and Foster, Ian"
  id: "publication-13"

- title: "FedCache: Proxy Caching in Wide-Area Scientific Database Federations"
  Authors: "Tanu Malik, Xiaodan Wang, and Randal Burns"
  Description: "The performance of caching algorithms depends heavily on the architecture of the host system on which they are implemented. Various system and design issues can reduce the overall performance. In this paper, we describe architectural components of the FedCache system. FedCache integrates the bypass-yield cache framework into the World Wide Telescope, a real-world, scientific database federation. Caching will increase the scale of the federation and allows its benefits to reach a wider community."
  bibAuthors: "Malik, Tanu and Wang, Xiaodan and Burns, Randal"
  id: "publication-14"

- title: "OpenSkyQuery and OpenSkyNode-the VO Framework to Federate Astronomy Archives"
  Authors: "William O'Mullane, Tamás Budavári, Nolan Li, Tanu Malik, Marıa A Nieto-Santisteban, Alexander S Szalay, and Aniruddha R Thakar"
  Conference: "Astronomical Data Analysis Software and Systems XIV"
  Volume: "347"
  Pages: "341"
  Description: "OpenSkyNode and ADQL are the major new steps in the Data Access layer of the Virtual Observatory. OpenSkyQuery (OSQ) allows cross matches between catalogs on registered nodes and supports the upload of lists of sources to be cross matched. This system utilizes the IVOA's nascent standard Astronomical Data Query Language (ADQL)."
  bibAuthors: "O'Mullane, William and Budavári, Tamás and Li, Nolan and Malik, Tanu and Nieto-Santisteban, Marıa A N and Szalay, Alexander S S and Thakar, Aniruddha R T"
  Year: 2005
  Month: "December"
  Date: 20051200
  id: "publication-15"

- title: "Efficient provenance alignment in reproduced executions"
  Authors: "Yuta Nakamura, Tanu Malik, and Ashish Gehani"
  Conference: "12th International Workshop on Theory and Practice of Provenance (TaPP 2020)"
  Description: "Reproducing experiments entails repeating experiments with changes. Changes, such as a change in input arguments, a change in the invoking environment, or a change due to nondeterminism in the runtime may alter results. If results alter significantly, perusing them is not sufficient—users must analyze the impact of a change and determine if the experiment computed the same steps. Making fine-grained, stepwise comparisons can be both challenging and time-consuming. In this paper, we compare a reproduced execution with recorded system provenance of the original execution, and determine provenance alignment. The alignment is based on comparing the specific location in the program, the control flow of the execution, and data inputs. Experiments show that the alignment method has a low overhead to compute a match and realigns with a small look-ahead buffer."
  bibAuthors: "Nakamura, Yuta and Malik, Tanu and Gehani, Ashish"
  Year: 2020
  Date: 20200000
  id: "publication-16"

- title: "Sketching distributed data provenance"
  Authors: "Tanu Malik, Ashish Gehani, Dawood Tariq, and Fareed Zaffar"
  Book: "Data Provenance and Data Management in eScience"
  Pages: "85-107"
  Publisher: "Springer, Berlin, Heidelberg"
  Description: "Users can determine the precise origins of their data by collecting detailed provenance records. However, auditing at a finer grain produces large amounts of metadata. To efficiently manage the collected provenance, several provenance management systems, including SPADE, record provenance on the hosts where it is generated. Distributed provenance raises the issue of efficient reconstruction during the query phase. Recursively querying provenance metadata or computing its transitive closure is known to have limited scalability and cannot be used for large provenance graphs. We present
           
            matrix filters
           
           , which are novel data structures for representing graph information, and demonstrate their utility for improving query efficiency with experiments on provenance metadata gathered while executing distributed workflow applications."
  bibAuthors: "Malik, Tanu and Gehani, Ashish and Tariq, Dawood and Zaffar, Fareed"
  Year: 2013
  Date: 20130000
  id: "publication-17"

- title: "Report on the first international workshop on incremental re-computation: Provenance and beyond"
  Authors: "Paolo Missier, Tanu Malik, and Jacek Cala"
  Journal: "ACM SIGMOD Record"
  Volume: "47"
  Issue: "4"
  Pages: "35-38"
  Publisher: "ACM"
  Description: "In the last decade, advances in computing have deeply transformed data processing. Increasingly systems aim to process massive amounts of data efficiently, often with fast response times that are typically characterised by the 4V's, i.e., Volume, Variety, Velocity, and Veracity. While fast data processing is desirable, it is also often the case that the outcomes of computationally expensive processes become obsolete over time, due to changes in inputs, reference datasets, tools, libraries, and deployment environment. Given massive data processing, such changes must be carefully accounted for, and their impact on original computation assessed, to determine how much re-computation is needed in response to changes."
  bibAuthors: "Missier, Paolo and Malik, Tanu and Cala, Jacek"
  Year: 2019
  Month: "May"
  Day: 17
  Date: 20190517
  id: "publication-18"

- title: "Design of Community Resource Inventories as a Component of Scalable Earth Science Infrastructure: Experience of the Earthcube CINERGI Project"
  Authors: "Ilya Zaslavsky, Stephen M Richard, DW Valentine Jr, Jeffrey S Grethe, Leslie Hsu, Tanu Malik, Luis E Bermudez, Amarnath Gupta, KA Lehnert, Thomas Whitenack, Ibrahim Burak Ozyurt, Christopher Condit, Raquel Calderon, and Leah Musil"
  Journal: "AGU Fall Meeting Abstracts"
  Volume: "2014"
  Pages: "IN24A-09"
  Description: "EarthCube is envisioned as a cyberinfrastructure that fosters new, transformational geoscience by enabling sharing, understanding and scientifically-sound and efficient re-use of formerly unconnected data resources, software, models, repositories, and computational power. Its purpose is to enable science enterprise and workforce development via an extensible and adaptable collaboration and resource integration framework. A key component of this vision is development of comprehensive inventories supporting resource discovery and re-use across geoscience domains. The goal of the EarthCube CINERGI (Community Inventory of EarthCube Resources for Geoscience Interoperability) project is to create a methodology and assemble a large inventory of high-quality information resources with standard metadata descriptions and traceable provenance. The inventory is compiled from metadata catalogs …"
  bibAuthors: "Zaslavsky, Ilya and Richard, Stephen M R and Jr, DW V J and Grethe, Jeffrey S G and Hsu, Leslie and Malik, Tanu and Bermudez, Luis E B and Gupta, Amarnath and Lehnert, KA and Whitenack, Thomas and Ozyurt, Ibrahim B O and Condit, Christopher and Calderon, Raquel and Musil, Leah"
  Year: 2014
  Month: "December"
  Date: 20141200
  id: "publication-19"

- title: "CHEX: Multiversion Replay with Ordered Checkpoints"
  Authors: "Naga Nithin Manne, Shilvi Satpati, Tanu Malik, Amitabha Bagchi, Ashish Gehani, and Amitabh Chaudhary"
  Journal: "arXiv preprint arXiv:2202.08429"
  Description: "In scientific computing and data science disciplines, it is often necessary to share application workflows and repeat results. Current tools containerize application workflows, and share the resulting container for repeating results. These tools, due to containerization, do improve sharing of results. However, they do not improve the efficiency of replay. In this paper, we present the multiversion replay problem which arises when multiple versions of an application are containerized, and each version must be replayed to repeat results. To avoid executing each version separately, we develop CHEX, which checkpoints program state and determines when it is permissible to reuse program state across versions. It does so using system call-based execution lineage. Our capability to identify common computations across versions enables us to consider optimizing replay using an in-memory cache, based on a checkpoint-restore-switch system. We show the multiversion replay problem is NP-hard, and propose efficient heuristics for it. CHEX reduces overall replay time by sharing common computations but avoids storing a large number of checkpoints. We demonstrate that CHEX maintains lightweight package sharing, and improves the total time of multiversion replay by 50% on average."
  bibAuthors: "Manne, Naga N M and Satpati, Shilvi and Malik, Tanu and Bagchi, Amitabha and Gehani, Ashish and Chaudhary, Amitabh"
  Year: 2022
  Month: "February"
  Day: 17
  Date: 20220217
  id: "publication-20"

- title: "Proactive Support for Large-Scale Data Exploration"
  Authors: "Mark Hereld, Tanu Malik, and Venkatram Vishwanath"
  Conference: "2013 IEEE International Symposium on Parallel & Distributed Processing, Workshops and Phd Forum"
  Pages: "2025-2034"
  Publisher: "IEEE"
  Description: "Computational science is generating increasingly unwieldy datasets created by complex and high-resolution simulations of physical, social, and economic systems. Traditional post processing of such large datasets requires high bandwidth to large storage resources. In situ processing approaches can reduce I/O requirements but steal processing cycles from the simulation and forsake interactive data exploration. The Fusion project aims to develop a new approach for exploring large-scale scientific datasets wherein the system actively assists the user in the data exploration process. A key component of the system is a software assistant that evaluates the stated and implied analysis goals of the scientist, observes the environment, models and proposes actions to be taken, and orchestrates the generation of analysis and visualization products for the user. These products are managed and made available to the …"
  bibAuthors: "Hereld, Mark and Malik, Tanu and Vishwanath, Venkatram"
  Year: 2013
  Month: "May"
  Day: 20
  Date: 20130520
  id: "publication-21"

- title: "Committees of the International Workshop on Analyzing and Improving Collaborative eScience with Social Networks (eSoN 13)"
  Authors: "Kyle Chard, Tanu Malik, Simon Caton, Wei Tan, Christine Borgman, Ian Foster, Gerhard Klimeck, Omer Rana, Kris Bubendorfer, Junwei Cao, Justin Cappos, Zhen Chen, Roberto M Cesar Jr, Christian Haas, Nicolas Kourtellis, Xitong Li, Xuanzhe Liu, Nicholas Loulloudes, Jesus P Mena-Chalco, Paolo Missier, Iman Saleh Moustafa, Victoria Stodden, Jie Tang, Michela Taufer, Jianwu Wang, Wenjun Wu, and Hui Zhang"
  Description: "Workshop Committees IEEE.org Help Cart Jobs Board Create Account Toggle navigation IEEE 
Computer Society Digital Library Jobs Tech News Resource Center Press Room Browse By 
Date Advertising About Us IEEE IEEE Computer Society IEEE Computer Society Digital Library 
My Subscriptions Magazines Journals Conference Proceedings Institutional Subscriptions 
IEEE IEEE Computer Society More Jobs Tech News Resource Center Press Room Browse By 
Date Advertising About Us Cart All Advanced Search Conference Cover Image Download 
1.Home 2.Proceedings 3.e-science 2013 Workshop Committees 2013, pp. xiv-xiv, DOI 
Bookmark: 10.1109/eScience.2013.6 Keywords Authors Abstract Provides a listing of current 
committee members and society officers. Committees of the International Workshop on 
Analyzing and ,Improving Collaborative eScience with Social Networks ,(eSoN 13) ,Organizers ,…"
  bibAuthors: "Chard, Kyle and Malik, Tanu and Caton, Simon and Tan, Wei and Borgman, Christine and Foster, Ian and Klimeck, Gerhard and Rana, Omer and Bubendorfer, Kris and Cao, Junwei and Cappos, Justin and Chen, Zhen and Jr, Roberto M C J and Haas, Christian and Kourtellis, Nicolas and Li, Xitong and Liu, Xuanzhe and Loulloudes, Nicholas and Mena-Chalco, Jesus P M and Missier, Paolo and Moustafa, Iman S M and Stodden, Victoria and Tang, Jie and Taufer, Michela and Wang, Jianwu and Wu, Wenjun and Zhang, Hui"
  id: "publication-22"

- title: "Practical passive lossy link inference"
  Authors: "Alexandros Batsakis, Tanu Malik, and Andreas Terzis"
  Conference: "International Workshop on Passive and Active Network Measurement"
  Pages: "362-367"
  Publisher: "Springer, Berlin, Heidelberg"
  Description: "We propose a practical technique for the identification of lossy network links. Our scheme is based on a function that computes the likelihood of each link to be lossy. This function mainly depends on the number of times a link appears in lossy paths and on the relative loss rates of these paths. Preliminary simulation results show that our solution achieves accuracy comparable to statistical methods (e.g. Bayesian) at significantly lower running time."
  bibAuthors: "Batsakis, Alexandros and Malik, Tanu and Terzis, Andreas"
  Year: 2005
  Month: "March"
  Day: 31
  Date: 20050331
  id: "publication-23"

- title: "EarthCube IA: Collaborative Proposal: Integrated GeoScience Observatory"
  Authors: "Tanu Malik"
  Description: "英文摘要 The habitability of planet Earth depends on a complex interaction between interior regions, solid surface, oceans, atmosphere, near-earth space environment, and Sun. Yet, study of this Sun-Earth system is traditionally broken up into separate geoscience disciplines, so that progress can be made by scientists working in reasonably-sized communities that share a common language and base of knowledge. To broach the bigger question of the interaction of the subsystems studied by the separate communities, it is necessary to overcome the barriers of communication posed by different observational instruments, software tools for interpreting data, and modeling methods. In answer to this challenge, the Integrated Geoscience Observatory is a pilot project that creates an online platform for integrating data and associated software tools contributed by separate geoscience research communities, into a unified …"
  bibAuthors: "Malik, Tanu"
  Year: 2016
  Month: "September"
  Day: 1
  Date: 20160901
  id: "publication-24"

- title: "GEN: a database interface generator for HPC programs"
  Authors: "Quan Pham, and Tanu Malik"
  Book: "Proceedings of the 27th International Conference on Scientific and Statistical Database Management"
  Pages: "1-5"
  Description: "In this paper, we present GEN an interface generator that takes user-supplied C declarations and provides the necessary interface needed to load and access data from common scientific array databases such as SciDB and Rasdaman. GEN can be used for storing the output of parallel computations directly into the database and automates the previously used inefficient ingestion process which requires development of special database schemas for each computation. Further, GEN requires no modifications to existing C code and can build a working interface in minutes. We show how GEN can be used for Cosmology analysis programs to output data sets in real-time to a database and use for subsequent analysis. We show that GEN introduces modest overhead in program execution but is more efficient than writing to files and then loading. More significantly, it significantly reduces the programmatic overhead of …"
  bibAuthors: "Pham, Quan and Malik, Tanu"
  Year: 2015
  Month: "June"
  Day: 29
  Date: 20150629
  id: "publication-25"

- title: "Cyberinfrastructure to Support Collaborative and Reproducible Computational Hydrologic Modeling"
  Authors: "Jonathan L Goodall, Anthony M Castronova, Christina Bandaragoda, Mohamed M Morsy, Jeffrey Michael Sadler, Bakinam Essawy, David G Tarboton, Tanu Malik, Bart Nijssen, Martyn P Clark, Yan Liu, and Shao-Wen Wang"
  Journal: "AGU Fall Meeting Abstracts"
  Volume: "2017"
  Pages: "H14H-05"
  Description: "Creating cyberinfrastructure to support reproducibility of computational hydrologic models is an important research challenge. Addressing this challenge requires open and reusable code and data with machine and human readable metadata, organized in ways that allow others to replicate results and verify published findings. Specific digital objects that must be tracked for reproducible computational hydrologic modeling include (1) raw initial datasets,(2) data processing scripts used to clean and organize the data,(3) processed model inputs,(4) model results, and (5) the model code with an itemization of all software dependencies and computational requirements. HydroShare is a cyberinfrastructure under active development designed to help users store, share, and publish digital research products in order to improve reproducibility in computational hydrology, with an architecture supporting hydrologic-specific …"
  bibAuthors: "Goodall, Jonathan L G and Castronova, Anthony M C and Bandaragoda, Christina and Morsy, Mohamed M M and Sadler, Jeffrey M S and Essawy, Bakinam and Tarboton, David G T and Malik, Tanu and Nijssen, Bart and Clark, Martyn P C and Liu, Yan and Wang, Shao-Wen"
  Year: 2017
  Month: "December"
  Date: 20171200
  id: "publication-26"

- title: "Wagging the long tail of earth science: Why we need an earth science data web, and how to build it"
  Authors: "Ian Foster, Daniel S Katz, Tanu Malik, and Peter Fox"
  Description: "Consider Alice, a geoscientist, who wants to investigate the role of sea surface temperatures (SSTs) on anomalous atmospheric circulations and associated precipitation in the tropics. She hypothesizes that nonlinear dynamics can help her model transport processes propagated long distances through the atmosphere or ocean, and asks a graduate student to obtain daily weather, land-cover, and other environmental data products that may be used to validate her hypothesis.
          

           Like the vast majority of NSF-funded researchers (see Table 1), Alice works with limited resources. Indeed, her laboratory comprises just herself, a couple of graduate students, an undergraduate, and a technician. In the absence of suitable expertise and infrastructure, the apparently simple task that she assigns to her graduate student becomes an information discovery and management nightmare. Data are either not available or are of poor quality. Downloading and transforming datasets takes weeks. Alice then faces new challenges. Will these new data enrich her compute-intensive model, or simply propagate errors? Or should they seek other, higher-resolution datasets? What software can she use to help answer these questions? We cannot blame Alice if she ultimately abandons this promising avenue of research."
  bibAuthors: "Foster, Ian and Katz, Daniel S K and Malik, Tanu and Fox, Peter"
  Year: 2012
  Date: 20120000
  id: "publication-27"

- title: "The SDSS skyserver: public access to the sloan digital sky server data"
  Authors: "Alexander S Szalay, Jim Gray, Ani R Thakar, Peter Z Kunszt, Tanu Malik, Jordan Raddick, Christopher Stoughton, and Jan vandenBerg"
  Book: "Proceedings of the 2002 ACM SIGMOD international conference on Management of data"
  Pages: "570-581"
  Description: "The SkyServer provides Internet access to the public Sloan Digital Sky Survey (SDSS) data for both astronomers and for science education. This paper describes the SkyServer goals and architecture. It also describes our experience operating the SkyServer on the Internet. The SDSS data is public and well-documented so it makes a good test platform for research on database algorithms and performance."
  bibAuthors: "Szalay, Alexander S S and Gray, Jim and Thakar, Ani R T and Kunszt, Peter Z K and Malik, Tanu and Raddick, Jordan and Stoughton, Christopher and vandenBerg, Jan"
  Year: 2002
  Month: "June"
  Day: 3
  Date: 20020603
  id: "publication-28"

- title: "Distributed data provenance for large-scale data-intensive computing"
  Authors: "Dongfang Zhao, Chen Shou, Tanu Maliky, and Ioan Raicu"
  Conference: "2013 IEEE International Conference on Cluster Computing (CLUSTER)"
  Pages: "1-8"
  Publisher: "IEEE"
  Description: "It has become increasingly important to capture and understand the origins and derivation of data (its provenance). A key issue in evaluating the feasibility of data provenance is its performance, overheads, and scalability. In this paper, we explore the feasibility of a general metadata storage and management layer for parallel file systems, in which metadata includes both file operations and provenance metadata. We experimentally investigate the design optimality-whether provenance metadata should be loosely-coupled or tightly integrated with a file metadata storage systems. We consider two systems that have applied similar distributed concepts to metadata management, but focusing singularly on kind of metadata: (i) FusionFS, which implements a distributed file metadata management based on distributed hash tables, and (ii) SPADE, which uses a graph database to store audited provenance data and …"
  bibAuthors: "Zhao, Dongfang and Shou, Chen and Maliky, Tanu and Raicu, Ioan"
  Year: 2013
  Month: "September"
  Day: 23
  Date: 20130923
  id: "publication-29"

- title: "SkyQuery--A Prototype Distributed Query Web Service for the Virtual Observatory"
  Authors: "Tamás Budavári, Tanu Malik, AS Szalay, AR Thakar, and Jim Gray"
  Conference: "Astronomical Data Analysis Software and Systems XII"
  Volume: "295"
  Pages: "31"
  Description: "We present SkyQuery’, a distributed query system for astronomical catalogs. Using XML Web Services, SkyQuery federates databases at different locations and provides a programming and user interface to access catalog data as easily as if they were in a single database"
  bibAuthors: "Budavári, Tamás and Malik, Tanu and Szalay, AS and Thakar, AR and Gray, Jim"
  Year: 2003
  Date: 20030000
  id: "publication-30"

- title: "A workload-driven unit of cache replacement for mid-tier database caching"
  Authors: "Xiaodan Wang, Tanu Malik, Randal Burns, Stratos Papadomanolakis, and Anastassia Ailamaki"
  Conference: "International Conference on Database Systems for Advanced Applications"
  Pages: "374-385"
  Publisher: "Springer, Berlin, Heidelberg"
  Description: "Making multi-terabyte scientific databases publicly accessible over the Internet is increasingly important in disciplines such as Biology and Astronomy. However, contention at a centralized, backend database is a major performance bottleneck, limiting the scalability of Internet-based, database applications. Mid-tier caching reduces contention at the backend database by distributing database operations to the cache. To improve the performance of mid-tier caches, we propose the caching of query prototypes, a workload-driven unit of cache replacement in which the cache object is chosen from various classes of queries in the workload. In existing mid-tier caching systems, the storage organization in the cache is statically defined. Our approach adapts cache storage to workload changes, requires no prior knowledge about the workload, and is transparent to the application. Experiments over a one-month, 1 …"
  bibAuthors: "Wang, Xiaodan and Malik, Tanu and Burns, Randal and Papadomanolakis, Stratos and Ailamaki, Anastassia"
  Year: 2007
  Month: "April"
  Day: 9
  Date: 20070409
  id: "publication-31"

- title: "Lifetime measurement with LaBr {sub 3}(Ce) detector"
  Authors: "D Banerjee, SK Das, A Saha, T Bhattacharjee, SR Banerjee, and T Malik"
  Description: "LaBr{sub 3}(Ce) detector, known as BrilLanCe 380, is the best scintillator available till date for the applications related to gamma ray spectroscopy. Very high light output (∼ 63000 photons / MeV) and a low decay time (∼ 20 ns ) make it superior even compared to germanium detectors in several applications."
  bibAuthors: "Banerjee, D and Das, SK and Saha, A and Bhattacharjee, T and Banerjee, SR and Malik, T"
  Year: 2013
  Month: "December"
  Day: 15
  Date: 20131215
  id: "publication-32"

- title: "Improving Reproducibility of Distributed Computational Experiments"
  Authors: "Quan Pham, Tanu Malik, Dai Hai Ton That, and Andrew Youngdahl"
  Book: "Proceedings of the First International Workshop on Practical Reproducible Evaluation of Computer Systems"
  Pages: "1-6"
  Description: "Conference and journal publications increasingly require experiments associated with a submitted article to be repeatable. Authors comply to this requirement by sharing all associated digital artifacts, ie, code, data, and environment configuration scripts. To ease aggregation of the digital artifacts, several tools have recently emerged that automate the aggregation of digital artifacts by auditing an experiment execution and building a portable container of code, data, and environment. However, current tools only package non-distributed computational experiments. Distributed computational experiments must either be packaged manually or supplemented with sufficient documentation."
  bibAuthors: "Pham, Quan and Malik, Tanu and That, Dai H T T and Youngdahl, Andrew"
  Year: 2018
  Month: "June"
  Day: 11
  Date: 20180611
  id: "publication-33"

- title: "Sharing and reproducing database applications"
  Authors: "Quan Pham, Severin Thaler, Tanu Malik, Ian Foster, and Boris Glavic"
  Journal: "Proceedings of the VLDB Endowment"
  Volume: "8"
  Issue: "12"
  Pages: "1988-1991"
  Publisher: "VLDB Endowment"
  Description: "Sharing and repeating scientific applications is crucial for verifying claims, reproducing experimental results (e.g., to repeat a computational experiment described in a publication), and promoting reuse of complex applications. The predominant methods of sharing and making applications repeatable are building a companion web site and/or provisioning a virtual machine image (VMI). Recently,
           
            application virtualization
           
           (AV), has emerged as a light-weight alternative for sharing and efficient repeatability. AV approaches such as Linux Containers create a chroot-like environment [4], while approaches such as CDE [1] trace system calls during application execution to copy all binaries, data, and software dependencies into a self-contained package."
  bibAuthors: "Pham, Quan and Thaler, Severin and Malik, Tanu and Foster, Ian and Glavic, Boris"
  Year: 2015
  Month: "August"
  Day: 1
  Date: 20150801
  id: "publication-34"

- title: "A Black-Box Approach to Query Cardinality Estimation."
  Authors: "Tanu Malik, Randal C Burns, and Nitesh V Chawla"
  Conference: "CIDR"
  Pages: "56-67"
  Description: "We present a “black-box” approach to estimating query cardinality that has no knowledge of query execution plans and data distribution, yet provides accurate estimates. It does so by grouping queries into syntactic families and learning the cardinality distribution of that group directly from points in a high-dimensional input space constructed from the query’s attributes, operators, function arguments, aggregates, and constants. We envision an increasing need for such an approach in applications in which query cardinality is required for resource optimization and decision-making at locations that are remote from the data sources. Our primary case study is the Open SkyQuery federation of Astronomy archives, which uses a scheduling and caching mechanism at the mediator for execution of federated queries at remote sources. Experiments using real workloads show that the black-box approach produces accurate estimates and is frugal in its use of space and in computation resources. Also, the black-box approach provides dramatic improvements in the performance of caching in Open SkyQuery."
  bibAuthors: "Malik, Tanu and Burns, Randal C B and Chawla, Nitesh V C"
  Year: 2007
  Month: "January"
  Day: 7
  Date: 20070107
  id: "publication-35"

- title: "Ontology-based urban data exploration"
  Authors: "Booma Sowkarthiga Balasubramani, Vivek R Shivaprabhu, Smitha Krishnamurthy, Isabel F Cruz, and Tanu Malik"
  Book: "Proceedings of the 2nd ACM SIGSPATIAL Workshop on Smart Cities and Urban Analytics"
  Pages: "1-8"
  Description: "Cities are actively creating open data portals to enable predictive analytics of urban data. However, the large number of observable patterns that can be extracted as rules by techniques such as Association Rule Mining (ARM) makes the task of sifting through patterns a tedious and time-consuming task. In this paper, we explore the use of domain ontologies to:(i) filter and prune rules that are variations of a more general concept in the ontology, and (ii) replace groups of rules by a single general rule with the intent of downsizing the number of initial rules while preserving the semantics. We show how the combination of several methods reduces significantly the number of rules thus effectively allowing city administrators to use open data to generate patterns, use them for decision making, and better direct limited government resources."
  bibAuthors: "Balasubramani, Booma S B and Shivaprabhu, Vivek R S and Krishnamurthy, Smitha and Cruz, Isabel F C and Malik, Tanu"
  Year: 2016
  Month: "October"
  Day: 31
  Date: 20161031
  id: "publication-36"

- title: "Rediscovering EarthCube: Collaborate. Or collaborate not. There is no I"
  Authors: "Plato Smith II, Tanu Malik, and Gary Berg-Cross"
  Journal: "Digital Library Perspectives"
  Publisher: "Emerald Group Publishing Limited"
  Description: "Purpose
          

           The EarthCube Technology and Architecture Committee working groups needed current information on the development of existing EarthCube-funded projects (eg building blocks, conceptual designs, and research coordination networks) to fulfill the goals of the working groups (eg gap analysis, use cases, standards bodies and testbed). The aims of this study include a compilation of planned outcomes, an assessment of current work and an investigation of interests in research collaboration among select EarthCube-funded projects."
  bibAuthors: "II, Plato S I and Malik, Tanu and Berg-Cross, Gary"
  Year: 2016
  Month: "August"
  Day: 8
  Date: 20160808
  id: "publication-37"

- title: "Policy-based integration of provenance metadata"
  Authors: "Ashish Gehani, Dawood Tariq, Basim Baig, and Tanu Malik"
  Conference: "2011 IEEE International Symposium on Policies for Distributed Systems and Networks"
  Pages: "149-152"
  Publisher: "IEEE"
  Description: "Reproducibility has been a cornerstone of the scientific method for hundreds of years. The range of sources from which data now originates, the diversity of the individual manipulations performed, and the complexity of the orchestrations of these operations all limit the reproducibility that a scientist can ensure solely by manually recording their actions. We use an architecture where aggregation, fusion, and composition policies define how provenance records can be automatically merged to facilitate the analysis and reproducibility of experiments. We show that the overhead of collecting and storing provenance metadata can vary dramatically depending on the policy used to integrate it."
  bibAuthors: "Gehani, Ashish and Tariq, Dawood and Baig, Basim and Malik, Tanu"
  Year: 2011
  Month: "June"
  Day: 6
  Date: 20110606
  id: "publication-38"

- title: "Estimating Query Result Sizes for Bypass-Yield Caches"
  Authors: "Tanu Malik, Randal Burns, and Nitesh V Chawla"
  Description: "In proxy database caches–especially which minimize the amount of total network traffic–it is important to estimate the size of a query before making a caching decision. In principle, optimal cache performance can be obtained. On the other extreme, inaccurate estimates can render the cache ineffective.
          

           We present classification and regression over templates (CAROT), a general method for estimating query result sizes, which is suited to the resource-limited environments of proxy caches. CAROT estimates query result sizes by learning data distributions, not by examining or sampling data, but from observing workload: queries and their results. We have integrated CAROT into the proxy cache of the National Virtual Observatory (NVO) federation of astronomy databases. Experiments conducted in the NVO show that CAROT outperforms conventional estimation techniques and provides near-optimal cache performance."
  bibAuthors: "Malik, Tanu and Burns, Randal and Chawla, Nitesh V C"
  id: "publication-39"

- title: "Large scale data management for the sciences"
  Authors: "Tanu Malik"
  Institution: "The Johns Hopkins University"
  Description: "Traditional enterprises and novel scientific applications are accumulating petabyte-scale datasets, which makes the need for large-scale data management more pressing than ever. Geographic distribution of the datasets accompanied by complex demands on data makes large-scale data management challenging. This is especially true for sciences that model complex physical and biological phenomena using data from multiple sources."
  bibAuthors: "Malik, Tanu"
  Year: 2008
  Date: 20080000
  id: "publication-40"

- title: "Bypass caching: Making scientific databases good network citizens"
  Authors: "Tanu Malik, Randal Burns, and Amitabh Chaudhary"
  Conference: "21st International Conference on Data Engineering (ICDE'05)"
  Pages: "94-105"
  Publisher: "IEEE"
  Description: "Scientific database federations are geographically distributed and network bound. Thus, they could benefit from proxy caching. However, existing caching techniques are not suitable for their workloads, which compare and join large data sets. Existing techniques reduce parallelism by conducting distributed queries in a single cache and lose the data reduction benefits of performing selections at each database. We develop the bypass-yield formulation of caching, which reduces network traffic in wide-area database federations, while preserving parallelism and data reduction. Bypass-yield caching is altruistic; caches minimize the overall network traffic generated by the federation, rather than focusing on local performance. We present an adaptive, workload-driven algorithm for managing a bypass-yield cache. We also develop on-line algorithms that make no assumptions about workload: a k-competitive …"
  bibAuthors: "Malik, Tanu and Burns, Randal and Chaudhary, Amitabh"
  Year: 2005
  Month: "April"
  Day: 5
  Date: 20050405
  id: "publication-41"

- title: "SOLE: linking research papers with science objects"
  Authors: "Quan Pham, Tanu Malik, Ian Foster, Roberto Di Lauro, and Raffaele Montella"
  Conference: "International Provenance and Annotation Workshop"
  Pages: "203-208"
  Publisher: "Springer, Berlin, Heidelberg"
  Description: "We introduce Science Object Linking and Embedding (SOLE), a tool for linking research papers with associated
           
            science objects
           
           , such as source codes, datasets, annotations, workflows, packages, and virtual machine images. The objective of SOLE is to reduce the cost to an author of linking research papers with such science objects for the purpose of reproducible research. To this end, SOLE allows an author to use simple tags to delimit a science object to be associated with a research paper. It creates an adequate representation of the science object and manages a bibliography-like specification of science objects. Authors and readers can reference elements of this bibliography and associate them with phrases in the text of the research paper through a Web interface, in a similar manner to a traditional bibliography tool."
  bibAuthors: "Pham, Quan and Malik, Tanu and Foster, Ian and Lauro, Roberto D L and Montella, Raffaele"
  Year: 2012
  Month: "June"
  Day: 19
  Date: 20120619
  id: "publication-42"

- title: "Sciunits: Reusable Research Objects"
  Authors: "Tanu Malik, Zhihao Yuan, Bakinam Tarik Essawy, Anthony M Castronova, Tian Gan, David G Tarboton, Jonathan L Goodall, Scott Dale Peckham, Eunseo Choi, and Asti Bhatt"
  Journal: "AGU Fall Meeting Abstracts"
  Volume: "2018"
  Pages: "IN34B-10"
  Description: "Science is conducted collaboratively and often requires sharing of computational experiments. An experiment often includes diverse elements such as software, its past execution, provenance, and associated documentation. The notion of a``research object''implies aggregation and identification of such diverse elements of computational experiments. Mere aggregation is, however, not sufficient for the sharing of computational experiments. Other users must be able to easily recompute on these shared research objects. We will present the``sciunit'', a reusable research object in which aggregated content is tracked, secured and made recomputable in different environments. We describe a Git-like client that efficiently creates, stores, repeats, and reproduces sciunits. We show that sciunits repeat computational experiments with minimal storage and processing overhead."
  bibAuthors: "Malik, Tanu and Yuan, Zhihao and Essawy, Bakinam T E and Castronova, Anthony M C and Gan, Tian and Tarboton, David G T and Goodall, Jonathan L G and Peckham, Scott D P and Choi, Eunseo and Bhatt, Asti"
  Year: 2018
  Month: "December"
  Date: 20181200
  id: "publication-43"

- title: "Auditing and maintaining provenance in software packages"
  Authors: "Quan Pham, Tanu Malik, and Ian Foster"
  Conference: "International Provenance and Annotation Workshop"
  Pages: "97-109"
  Publisher: "Springer, Cham"
  Description: "Science projects are increasingly investing in computational reproducibility. Constructing software pipelines to demonstrate reproducibility is also becoming increasingly common. To aid the process of constructing pipelines, science project members often adopt reproducible methods and tools. One such tool is CDE, which is a software packaging tool that encapsulates source code, datasets and environments. However, CDE does not include information about origins of dependencies. Consequently when multiple CDE packages are combined and merged to create a software pipeline, several issues arise requiring an author to manually verify compatibility of distributions, environment variables, software dependencies and compiler options. In this work, we propose software provenance to be included as part of CDE so that resulting provenance-included CDE packages can be easily used for creating …"
  bibAuthors: "Pham, Quan and Malik, Tanu and Foster, Ian"
  Year: 2014
  Month: "June"
  Day: 9
  Date: 20140609
  id: "publication-44"

- title: "Content-defined Merkle Trees  for Efficient Container Delivery"
  Authors: "Yuta Nakamura, Raza Ahmad, and Tanu Malik"
  Conference: "28th IEEE International Conference on High Performance Computing, Data, & Analytics"
  Description: "Containerization simplifies the sharing and deployment of applications when environments change in the software delivery chain. To deploy an application, container delivery methods push and pull container images. These methods operate on file and layer (set of files) granularity, and introduce redundant data within a container. Several container operations such as upgrading, installing, and maintaining become inefficient, because of copying and provisioning of redundant data. In this paper, we reestablish recent results that block-level deduplication reduces the size of individual containers, by verifying the result using content-defined chunking. Block-level deduplication, however, does not improve the efficiency of push/pull operations which must determine the specific blocks to transfer. We introduce a content-defined Merkle Tree (CDMT) over deduplicated storage in a container. CDMT indexes deduplicated …"
  bibAuthors: "Nakamura, Yuta and Ahmad, Raza and Malik, Tanu"
  Year: 2020
  Date: 20200000
  id: "publication-45"

- title: "Adaptive physical design for curated archives"
  Authors: "Tanu Malik, Xiaodan Wang, Debabrata Dash, Amitabh Chaudhary, Anastasia Ailamaki, and Randal Burns"
  Conference: "International Conference on Scientific and Statistical Database Management"
  Pages: "148-166"
  Publisher: "Springer, Berlin, Heidelberg"
  Description: "We introduce AdaptPD, an automated physical design tool that improves database performance by continuously monitoring changes in the workload and adapting the physical design to suit the incoming workload. Current physical design tools are offline and require specification of a representative workload. AdaptPD is “always on” and incorporates online algorithms which profile the incoming workload to calculate the relative benefit of transitioning to an alternative design. Efficient query and transition cost estimation modules allow AdaptPD to quickly decide between various design configurations. We evaluate AdaptPD with the SkyServer Astronomy database using queries submitted by SkyServer’s users. Experiments show that AdaptPD adapts to changes in the workload, improves query performance substantially over offline tools, and introduces minor computational overhead."
  bibAuthors: "Malik, Tanu and Wang, Xiaodan and Dash, Debabrata and Chaudhary, Amitabh and Ailamaki, Anastasia and Burns, Randal"
  Year: 2009
  Month: "June"
  Day: 2
  Date: 20090602
  id: "publication-46"

- title: "Achieving Reproducible Computational Hydrologic Models by Integrating Scientific Cyberinfrastructures"
  Authors: "Bakinam T Essawy, Jonathan L Goodall, Mohamed M Morsy, Wesley Zell, Jeffrey Sadler, Tanu Malik, Zhihao Yuan, and Daniel Voce"
  Description: "Reproducibility of computational workflows is an important challenge that calls for open and reusable code and data, well-documented workflows, and controlled environments that allow others to verify published findings. HydroShare (http://www. hydroshare. org) and GeoTrust (http://geotrusthub. org/), two new cyberinfrastructure tools under active development, can be used to improve reproducibility in computational hydrology. HydroShare is a web-based system for sharing hydrologic data and model resources. HydroShare offers hydrologists the capability to upload model input data as resources, add hydrologic-specific metadata to these resources, and use the data directly within HydroShare for collaborative modeling using tools like JupyterHub. GeoTrust provides tools for scientists to efficiently reproduce, track and share geoscience applications by building ‘sciunit,’which are efficient, lightweight, self-contained packages of computational experiments that can be guaranteed to repeat or reproduce regardless of deployment challenges. We will present a use case example focusing on a workflow that uses the MODFLOW model to demonstrate how HydroShare and GeoTrust can be integrated to easily and efficiently reproduce computational workflows. This use case example automates pre-processing of model inputs, model execution, and post-processing of model output. This work demonstrates how the integration of HydroShare and Geotrust ensures the logical and physical preservation of computation workflows and that reproducibility can be achieved by replicating the original sciunit, modifying it to produce a new sciunit and finally …"
  bibAuthors: "Essawy, Bakinam T E and Goodall, Jonathan L G and Morsy, Mohamed M M and Zell, Wesley and Sadler, Jeffrey and Malik, Tanu and Yuan, Zhihao and Voce, Daniel"
  Year: 2018
  Date: 20180000
  id: "publication-47"

- title: "An Approach for Open and Reproducible Hydrological Modeling using Sciunit and HydroShare"
  Authors: "YoungDon Choi, Jonathan Goodall, Raza Ahmad, Tanu Malik, and David Tarboton"
  Journal: "EGU General Assembly Conference Abstracts"
  Pages: "EGU21-13763"
  Description: "It is widely acknowledged that the reproducibility of published computational results is critical to advancing science. Creating reproducible computational workflows, however, is burdensome and requires significant work to share the complete package that efficiently encapsulates all required data and software. Computational hydrology is one field that has seen rapid advancements through fast-evolving technologies for supporting increasingly complex computational hydrologic modeling and analysis. This growing model complexity, along with rapidly evolving underlying software technologies, makes the options and approaches for achieving computational reproducibility extremely challenging to settle. We argue that the technologies needed to achieve open and reproducible hydrological modeling can be grouped into three general categories: 1) data (and metadata) sharing, 2) containerizing computational …"
  bibAuthors: "Choi, YoungDon and Goodall, Jonathan and Ahmad, Raza and Malik, Tanu and Tarboton, David"
  Year: 2021
  Month: "April"
  Date: 20210400
  id: "publication-48"

- title: "PLI"
  Authors: "Dai Hai Ton That, James Wagner, Alexander Rasin, and Tanu Malik"
  Journal: "Distributed and Parallel Databases"
  Volume: "37"
  Issue: "1"
  Pages: "177-208"
  Publisher: "Springer US"
  Description: "Commercial cloud database services increase availability of data and provide reliable access to data. Routine database maintenance tasks such as clustering, however, increase the costs of hosting data on commercial cloud instances. Clustering causes an I/O burst; clustering in one-shot depletes I/O credit accumulated by an instance and increases the cost of hosting data. An unclustered database decreases query performance by scanning large amounts of data, gradually depleting I/O credits. In this paper, we introduce Physical Location Index Plus (PLI^+ PLI+), an indexing method for databases hosted on commercial cloud. PLI^+ PLI+ relies on internal knowledge of data layout, building a physical location index, which maps a range of physical co-locations with a range of attribute values to create approximately sorted buckets. As new data is inserted, writes are partitioned in memory based on incoming data …"
  bibAuthors: "That, Dai H T T and Wagner, James and Rasin, Alexander and Malik, Tanu"
  Year: 2019
  Month: "March"
  Date: 20190300
  id: "publication-49"

- title: "GeoBase: indexing NetCDF files for large-scale data analysis"
  Authors: "Tanu Malik"
  Book: "Big data management, technologies, and applications"
  Pages: "295-313"
  Publisher: "IGI Global"
  Description: "Data-rich scientific disciplines increasingly need end-to-end systems that ingest large volumes of data, make it quickly available, and enable processing and exploratory data analysis in a scalable manner. Key-value stores have attracted attention, since they offer highly available data storage, but must be engineered further for end-to-end support. In particular, key-value stores have minimal support for scientific data that resides in self-describing, array-based binary file formats and do not natively support scientific queries on multi-dimensional data. In this chapter, the authors describe GeoBase, which enables querying over scientific data by improving end-to-end support through two integrated, native components: a linearization-based index to enable rich scientific querying on multi-dimensional data and a plugin that interfaces key-value stores with array-based binary file formats. Experiments show that this end-to …"
  bibAuthors: "Malik, Tanu"
  Year: 2014
  Date: 20140000
  id: "publication-50"

- title: "Astronomical data query language: simple query protocol for the virtual observatory"
  Authors: "Naoki Yasuda, Yoshihiko Mizumoto, Masatoshi Ohishi, William O'Mullane, Tamás Budavári, Vivek Haridas, Nolan Li, Tanu Malik, AS Szalay, Martin Hill, Tony Linde, Bob Mann, and CG Page"
  Conference: "Astronomical Data Analysis Software and Systems (ADASS) XIII"
  Volume: "314"
  Pages: "293"
  Description: "The Astronomical Data Query Language (ADQL) is a proposed standard query language for the interoperability of the International Virtual Observatory. The data servers in the International Virtual"
  bibAuthors: "Yasuda, Naoki and Mizumoto, Yoshihiko and Ohishi, Masatoshi and O'Mullane, William and Budavári, Tamás and Haridas, Vivek and Li, Nolan and Malik, Tanu and Szalay, AS and Hill, Martin and Linde, Tony and Mann, Bob and Page, CG"
  Year: 2004
  Month: "July"
  Date: 20040700
  id: "publication-51"

- title: "Integrating scientific cyberinfrastructures to improve reproducibility in computational hydrology: Example for HydroShare and GeoTrust"
  Authors: "Bakinam T Essawy, Jonathan L Goodall, Wesley Zell, Daniel Voce, Mohamed M Morsy, Jeffrey Sadler, Zhihao Yuan, and Tanu Malik"
  Journal: "Environmental Modelling & Software"
  Volume: "105"
  Pages: "217-229"
  Publisher: "Elsevier"
  Description: "The reproducibility of computational environmental models is an important challenge that calls for open and reusable code and data, well-documented workflows, and controlled environments that allow others to verify published findings. This requires an ability to document and share raw datasets, data preprocessing scripts, model inputs, outputs, and the specific model code with all associated dependencies. HydroShare and GeoTrust, two scientific cyberinfrastructures under development, can be used to improve reproducibility in computational hydrology. HydroShare is a web-based system for sharing hydrologic data and models as digital resources including detailed, hydrologic-specific resource metadata. GeoTrust provides tools for scientists to efficiently reproduce and share geoscience applications. This paper outlines a use case example, which focuses on a workflow that uses the MODFLOW model, to …"
  bibAuthors: "Essawy, Bakinam T E and Goodall, Jonathan L G and Zell, Wesley and Voce, Daniel and Morsy, Mohamed M M and Sadler, Jeffrey and Yuan, Zhihao and Malik, Tanu"
  Year: 2018
  Month: "July"
  Day: 1
  Date: 20180701
  id: "publication-52"

- title: "Jaakkola, Hannu 434"
  Authors: "Toshiyuki Amagasa, Stefan Appel, Yusuke Ariyoshi, Yasuhito Asano, Ahmed Awad, Radim Baca, Peter Brezany, Alejandro Buchmann, Amitabh Chaudhary, Jiefeng Cheng, Reynold CK Cheng, Marek Ciglan, Hirohide Demura, Ke Deng, Guohui Ding, Jiˇrı Dokulil, Ibrahim Elsayed, Geoffrey Fox, Kazunori Fujimoto, Tatsuya Fujisaka, Ming Gao, Eirini Giannakidou, Dong Guoqing, David Hall, Jun’ichi Haruyama, Fumio Hattori, Yoshi-Yuki Hayashi, Yoshinori Hijikata, Naru Hirata, Neil Chue Hong, Toshihiko Horiike, Takeshi Horinouchi, Zhiqiu Huang, Yoshihiko Ichikawa, Kaori Ikeda, Yuka Isamoto, Junzo Kamahara, Hideyuki Kawashima, Yutaka Kidawara, KS Kim, Hiroyuki Kitagawa, Yoshinobu Kitamura, Y Kiyoki, Shinsuke Kodama, Isao Kojima, Tsuyoshi Koshiro, Samuel Kounev, Michal Krátký, Tadahiko Kumamoto, Ryong Lee, Ki-Joune Li, Yueting Li, Wenxin Liang, Chuan-Ming Liu, Jiaheng Lu, Hooran MahmoudiNasab, Tanu Malik, Qiang Ma, Ester Martin, Yuuki Matsui, Tsuneo Matsunaga, Riichiro Mizoguchi, and Irena Mlýnková"
  Journal: "Database Systems for Advanced Applications: 15th International Conference, DASFAA 2010, International Workshops: GDM, BenchmarX, MCIS, SNSMW, DIEW, UDM, Tsukuba, Japan, April 1-4, 2010, Revised Selected Papers"
  Volume: "6193"
  Pages: "471"
  Publisher: "Springer"
  Description: "Jaakkola, Hannu 434 Page 488 Aida, Kento 57 Amagasa, Toshiyuki 81 Appel, Stefan 203 
Ariyoshi, Yusuke 365 Asano, Yasuhito 20 Awad, Ahmed 33 Baca, Radim 179 Brezany, Peter 
69 Buchmann, Alejandro 203 Chaudhary, Amitabh 445 Cheng, Jiefeng 2 Cheng, Reynold CK 
2 Ciglan, Marek 45 Demura, Hirohide 58 Deng, Ke 117 Ding, Guohui 143 Dokulil, Jirı 168 
Elsayed, Ibrahim 69 Fox, Geoffrey 57 Fujimoto, Kazunori 296 Fujisaka, Tatsuya 374 Gao, Ming 
422 Giannakidou, Eirini 252 Guoqing, Dong 156 Hall, David 191 Haruyama, Jun’ichi 58 
Hattori, Fumio 353 Hayashi, Yoshi-Yuki 93 Hijikata, Yoshinori 239, 308, 346 Hirata, Naru 58 
Hong, Neil Chue 57 Horiike, Toshihiko 338 Horinouchi, Takeshi 93, 105 Huang, Zhiqiu 118 
Ichikawa, Yoshihiko 274 Ikeda, Kaori 346 Isamoto, Yuka 105 Jaakkola, Hannu 434 Kamahara, 
Junzo 365 Kawashima, Hideyuki 81 Kidawara, Yutaka 385 Kim, K.-S. 410 Kitagawa, Hiroyuki …"
  bibAuthors: "Amagasa, Toshiyuki and Appel, Stefan and Ariyoshi, Yusuke and Asano, Yasuhito and Awad, Ahmed and Baca, Radim and Brezany, Peter and Buchmann, Alejandro and Chaudhary, Amitabh and Cheng, Jiefeng and Cheng, Reynold C C and Ciglan, Marek and Demura, Hirohide and Deng, Ke and Ding, Guohui and Dokulil, Jiˇrı and Elsayed, Ibrahim and Fox, Geoffrey and Fujimoto, Kazunori and Fujisaka, Tatsuya and Gao, Ming and Giannakidou, Eirini and Guoqing, Dong and Hall, David and Haruyama, Jun’ichi and Hattori, Fumio and Hayashi, Yoshi-Yuki and Hijikata, Yoshinori and Hirata, Naru and Hong, Neil C H and Horiike, Toshihiko and Horinouchi, Takeshi and Huang, Zhiqiu and Ichikawa, Yoshihiko and Ikeda, Kaori and Isamoto, Yuka and Kamahara, Junzo and Kawashima, Hideyuki and Kidawara, Yutaka and Kim, KS and Kitagawa, Hiroyuki and Kitamura, Yoshinobu and Kiyoki, Y and Kodama, Shinsuke and Kojima, Isao and Koshiro, Tsuyoshi and Kounev, Samuel and Krátký, Michal and Kumamoto, Tadahiko and Lee, Ryong and Li, Ki-Joune and Li, Yueting and Liang, Wenxin and Liu, Chuan-Ming and Lu, Jiaheng and MahmoudiNasab, Hooran and Malik, Tanu and Ma, Qiang and Martin, Ester and Matsui, Yuuki and Matsunaga, Tsuneo and Mizoguchi, Riichiro and Mlýnková, Irena"
  Year: 2010
  Month: "August"
  Day: 17
  Date: 20100817
  id: "publication-53"

- title: "Plenario: A Spatio-Temporal Platform for Discovery and Exploration of Urban Science Data"
  Authors: "Tanu Malik, Charlie Catlett, William Houser Engler, Ian Foster, and Brett Goldstein"
  Journal: "2015 AGU Fall Meeting"
  Publisher: "AGU"
  bibAuthors: "Malik, Tanu and Catlett, Charlie and Engler, William H E and Foster, Ian and Goldstein, Brett"
  Year: 2015
  Month: "December"
  Day: 18
  Date: 20151218
  id: "publication-54"

- title: "SMDS 2021"
  Authors: "Menatalla Abuouf, Hussam Al Hamadi, Husam Al Hammadi, Maryam Al Shehhi, Abdelrahman Almahmoud, Marco Anisetti, Alessandro Balestrucci, Sylvio Barbon, Mahmoud Barhamgi, Valerio Bellandi, Emanuele Bellini, Paolo Ceravolo, Lu Cheng, Stelvio Cimato, Maurizio Colombo, Ernesto Damiani, Fulvio Frati, Min Fu, Tian Gao, Yingqiang Ge, Gabriele Gianini, Heyang Gong, Pei Guo, Jin-Kao Hao, Qiang He, Perpetus Jacques Houngbo, Youssef Iraqi, Utkarshani Jaimini, Bahman Javadi, Songkyoo Kim, Manuele Kirsch-Pinheiro, Hanane Lamaazi, Nan Li, Donghui Lin, Jianyi Lin, Hao Liu, Xingya Liu, Richard Lomotey, Jing Ma, Samira Maghool, Divyat Mahajan, Tanu Malik, Lara Mauri, Corrado Mio, Rabeb Mizouni, and Fatma Mohamed"
  Description: "Reviewers Page 1 Reviewers SMDS 2021 Menatalla Abuouf, Khalifa University Hussam Al 
Hamadi, Khalifa University Husam Al Hammadi, Khalifa University Maryam Al Shehhi, Khalifa 
University Abdelrahman Almahmoud, Technology Innovation Institute Marco Anisetti, University 
of Milan Alessandro Balestrucci, Gran Sasso Science Institute Sylvio Barbon, State University of 
Londrina Mahmoud Barhamgi, University of Lyon Valerio Bellandi, University of Milan Emanuele 
Bellini, Khalifa University Paolo Ceravolo, University of Milan Lu Cheng, Arizona State 
University Stelvio Cimato, University of Milan Maurizio Colombo, Khalifa University Ernesto 
Damiani, University of Milan Fulvio Frati, University of Milan Min Fu, LIZHI Inc. & Macquarie 
University Tian Gao, IBM Yingqiang Ge, Rutgers University Gabriele Gianini, University of 
Milan Heyang Gong, University of Science and Technology of China Pei Guo, University of …"
  bibAuthors: "Abuouf, Menatalla and Hamadi, Hussam A H and Hammadi, Husam A H and Shehhi, Maryam A S and Almahmoud, Abdelrahman and Anisetti, Marco and Balestrucci, Alessandro and Barbon, Sylvio and Barhamgi, Mahmoud and Bellandi, Valerio and Bellini, Emanuele and Ceravolo, Paolo and Cheng, Lu and Cimato, Stelvio and Colombo, Maurizio and Damiani, Ernesto and Frati, Fulvio and Fu, Min and Gao, Tian and Ge, Yingqiang and Gianini, Gabriele and Gong, Heyang and Guo, Pei and Hao, Jin-Kao and He, Qiang and Houngbo, Perpetus J H and Iraqi, Youssef and Jaimini, Utkarshani and Javadi, Bahman and Kim, Songkyoo and Kirsch-Pinheiro, Manuele and Lamaazi, Hanane and Li, Nan and Lin, Donghui and Lin, Jianyi and Liu, Hao and Liu, Xingya and Lomotey, Richard and Ma, Jing and Maghool, Samira and Mahajan, Divyat and Malik, Tanu and Mauri, Lara and Mio, Corrado and Mizouni, Rabeb and Mohamed, Fatma"
  id: "publication-55"

- title: "GeoTrust Hub: A Platform For Sharing And Reproducing Geoscience Applications"
  Authors: "Tanu Malik, David G Tarboton, Jonathan L Goodall, Eunseo Choi, Asti Bhatt, Scott Dale Peckham, Ian Foster, DH Ton That, B Essawy, Z Yuan, PK Dash, Gabriel Fils, Tian Gan, Oluwaseun Idowu Fadugba, Arushi Saxena, and Todd Alan Valentic"
  Journal: "AGU Fall Meeting Abstracts"
  Volume: "2017"
  Pages: "IN43A-0068"
  Description: "Recent requirements of scholarly communication emphasize the reproducibility of scientific claims. Text-based research papers are considered poor mediums to establish reproducibility. Papers must be accompanied by research objects, aggregation of digital artifacts that together with the paper provide an authoritative record of a piece of research. We will present GeoTrust Hub (http://geotrusthub. org), a platform for creating, sharing, and reproducing reusable research objects. GeoTrust Hub provides tools for scientists to creategeounits'--reusable research objects. Geounits are self-contained, annotated, and versioned containers that describe and package computational experiments in an efficient and light-weight manner. Geounits can be shared on public repositories such as HydroShare and FigShare, and also using their respective APIs reproduced on provisioned clouds. The latter feature enables science …"
  bibAuthors: "Malik, Tanu and Tarboton, David G T and Goodall, Jonathan L G and Choi, Eunseo and Bhatt, Asti and Peckham, Scott D P and Foster, Ian and That, DH T T and Essawy, B and Yuan, Z and Dash, PK and Fils, Gabriel and Gan, Tian and Fadugba, Oluwaseun I F and Saxena, Arushi and Valentic, Todd A V"
  Year: 2017
  Month: "December"
  Date: 20171200
  id: "publication-56"

- title: "Improving the efficiency of subset queries on raster images"
  Authors: "Tanu Malik, Neil Best, Joshua Elliott, Ravi Madduri, and Ian Foster"
  Book: "Proceedings of the ACM SIGSPATIAL Second International Workshop on High Performance and Distributed Geographic Information Systems"
  Pages: "34-37"
  Description: "We propose a parallel method to accelerate the performance of subset queries on raster images. The method, based on map-reduce paradigm, includes two principles from database management systems to improve the performance of subset queries. First, we employ column-oriented storage format for storing locationand weather variables. Second, we improve data locality by storing multidimensional attributes such as space and time in a Hilbert order instead of a serial, row-wise order. We implement the principles in a map-reduce environment, maintaining compatibility with the replication and scheduling constraints. We show through experiments that the techniques improve data locality and increase performance of subset queries, respectively, by 5x and 2x."
  bibAuthors: "Malik, Tanu and Best, Neil and Elliott, Joshua and Madduri, Ravi and Foster, Ian"
  Year: 2011
  Month: "November"
  Day: 1
  Date: 20111101
  id: "publication-57"

- title: "A taxonomy for reproducible and replicable research in environmental modelling"
  Authors: "Bakinam T Essawy, Jonathan L Goodall, Daniel Voce, Mohamed M Morsy, Jeffrey M Sadler, Young Don Choi, David G Tarboton, and Tanu Malik"
  Journal: "Environmental Modelling & Software"
  Volume: "134"
  Pages: "104753"
  Publisher: "Elsevier"
  Description: "Despite the growing acknowledgment of reproducibility crisis in computational science, there is still a lack of clarity around what exactly constitutes a reproducible or replicable study in many computational fields, including environmental modelling. To this end, we put forth a taxonomy that defines an environmental modelling study as being either 1) repeatable, 2) runnable, 3) reproducible, or 4) replicable. We introduce these terms with illustrative examples from hydrology using a hydrologic modelling framework along with cyberinfrastructure aimed at fostering reproducibility. Using this taxonomy as a guide, we argue that containerization is an important but lacking component needed to achieve the goal of computational reproducibility in hydrology and environmental modelling. Examples from hydrology are provided to demonstrate how new tools, including a user-friendly tool for containerization of computational …"
  bibAuthors: "Essawy, Bakinam T E and Goodall, Jonathan L G and Voce, Daniel and Morsy, Mohamed M M and Sadler, Jeffrey M S and Choi, Young D C and Tarboton, David G T and Malik, Tanu"
  Year: 2020
  Month: "December"
  Day: 1
  Date: 20201201
  id: "publication-58"

- title: "Workload-Aware histograms for remote applications"
  Authors: "Tanu Malik, and Randal Burns"
  Conference: "International Conference on Data Warehousing and Knowledge Discovery"
  Pages: "402-412"
  Publisher: "Springer, Berlin, Heidelberg"
  Description: "Recently several database-based applications have emerged that are remote from data sources and need accurate histograms for query cardinality estimation. Traditional approaches for constructing histograms require complete access to data and are I/O and network intensive, and therefore no longer apply to these applications. Recent approaches use queries and their feedback to construct and maintain “workload aware” histograms. However, these approaches either employ heuristics, thereby providing no guarantees on the overall histogram accuracy, or rely on detailed query feedbacks, thus making them too expensive to use. In this paper, we propose a novel, incremental method for constructing histograms that uses minimum feedback and guarantees minimum overall residual error. Experiments on real, high dimensional data shows 30-40% higher estimation accuracy over currently known …"
  bibAuthors: "Malik, Tanu and Burns, Randal"
  Year: 2008
  Month: "September"
  Day: 2
  Date: 20080902
  id: "publication-59"

- title: "NONUS: A No-Onus Platform for Generating Grant Reports"
  Authors: "Tanu Malik, Ian Foster, Andrey Rzhetsky, Jacob Foster, and James Evans"
  Conference: "2010 Sixth IEEE International Conference on e-Science Workshops"
  Pages: "136-140"
  Publisher: "IEEE"
  Description: "Advancements in science and technology are rapidly disseminated through publications, patents, blogs, and the social networks. However, the process behind creating the science or technology is hardly curated. This is increasingly becoming a bottleneck for federal agencies who not only fund the science projects and monitor their progress but also make science policy decisions to regulate fundings in various areas. Most federal agencies, currently, are made aware of science advancements through year-end reports that are submitted by the investigators of the research project. To aid federal agencies in monitoring science projects and timely understand the overall impact of science we are creating NONUS, a no-onus platform that compiles data about a science project from a variety of data sources to generate a report This includes Web data sources, patent databases, institutional data, and the federal agencies …"
  bibAuthors: "Malik, Tanu and Foster, Ian and Rzhetsky, Andrey and Foster, Jacob and Evans, James"
  Year: 2010
  Month: "December"
  Day: 7
  Date: 20101207
  id: "publication-60"

- title: "Automated physical design in database caches"
  Authors: "Tanu Malik, Xiaodan Wang, Randal Burns, Debabrata Dash, and Anastasia Ailamaki"
  Conference: "2008 IEEE 24th International Conference on Data Engineering Workshop"
  Pages: "27-34"
  Publisher: "IEEE"
  Description: "Performance of proxy caches for database federations that serve a large number of users is crucially dependent on its physical design. Current techniques, automated or otherwise, for physical design depend on the identification of a representative workload. In proxy caches, however, such techniques are inadequate since workload characteristics change rapidly. This is remarkably shown at the proxy cache of SkyQuery, an Astronomy federation, which receives a continuously evolving workload. We present novel techniques for automated physical design that adapt with the workload and balance the performance benefits of physical design decisions with the cost of implementing these decisions. These include both competitive and incremental algorithms that optimize the combined cost of query evaluation and making physical design changes. Our techniques are general in that they do not make assumptions …"
  bibAuthors: "Malik, Tanu and Wang, Xiaodan and Burns, Randal and Dash, Debabrata and Ailamaki, Anastasia"
  Year: 2008
  Month: "April"
  Day: 7
  Date: 20080407
  id: "publication-61"

- title: "Web services for the virtual observatory"
  Authors: "Alexander S Szalay, Tamás Budavári, Tanu Malik, Jim Gray, and Ani R Thakar"
  Conference: "Virtual Observatories"
  Volume: "4846"
  Pages: "124-132"
  Publisher: "SPIE"
  Description: "Web Services form a new, emerging paradigm to handle distributed access to resources over the Internet. There are platform independent standards (SOAP, WSDL), which make the developers' task considerably easier. This article discusses how web services could be used in the context of the Virtual Observatory. We envisage a multi-layer architecture, with interoperating services. A well-designed lower layer consisting of simple, standard services implemented by most data providers will go a long way towards establishing a modular architecture. More complex applications can be built upon this core layer. We present two prototype applications, the SdssCutout and the SkyQuery as examples of this layered architecture."
  bibAuthors: "Szalay, Alexander S S and Budavári, Tamás and Malik, Tanu and Gray, Jim and Thakar, Ani R T"
  Year: 2002
  Month: "December"
  Day: 16
  Date: 20021216
  id: "publication-62"

- title: "Detecting database file tampering through page carving"
  Authors: "James Wagner, Alexander Rasin, Karen Heart, Tanu Malik, Jacob Furst, and Jonathan Grier"
  Journal: "21st International Conference on Extending Database Technology"
  Description: "Database Management Systems (DBMSes) secure data against regular users through defensive mechanisms such as access control, and against privileged users with detection mechanisms such as audit logging. Interestingly, these security mechanisms are built into the DBMS and are thus only useful for monitoring or stopping operations that are executed through the DBMS API. Any access that involves directly modifying database files (at file system level) would, by definition, bypass any and all security layers built into the DBMS itself. In this paper,we propose and evaluate an approach that detects direct modifications to database files that have already bypassed the DBMS and its internal security mechanisms. Our approach applies forensic analysis to first validate database indexes and then compares index state with data in the DBMS tables. We show that indexes are much more difficult to modify and can be further fortified with hashing. Our approach supports most relational DBMSes by leveraging index structures that are already built into the system to detect database storage tampering that would currently remain undetectable."
  bibAuthors: "Wagner, James and Rasin, Alexander and Heart, Karen and Malik, Tanu and Furst, Jacob and Grier, Jonathan"
  Year: 2018
  Month: "March"
  Date: 20180300
  id: "publication-63"

- title: "Efficient querying of distributed provenance stores"
  Authors: "Ashish Gehani, Minyoung Kim, and Tanu Malik"
  Book: "Proceedings of the 19th ACM International Symposium on High Performance Distributed Computing"
  Pages: "613-621"
  Description: "Current projects that automate the collection of provenance information use a centralized architecture for managing the resulting metadata-that is, provenance is gathered at remote hosts and submitted to a central provenance management service. In contrast, we are developing a completely decentralized system with each computer maintaining the authoritative repository of the provenance gathered on it. Our model has several advantages, such as scaling to large amounts of metadata generation, providing low-latency access to provenance metadata about local data, avoiding the need for synchronization with a central service after operating while disconnected from the network, and letting users retain control over their data provenance records. We describe the SPADE project's support for tracking data provenance in distributed environments, including how queries can be optimized with provenance sketches …"
  bibAuthors: "Gehani, Ashish and Kim, Minyoung and Malik, Tanu"
  Year: 2010
  Month: "June"
  Day: 21
  Date: 20100621
  id: "publication-64"

- title: "Brave New World: Data Intensive Science with SDSS and the VO"
  Authors: "AR Thakar, AS Szalay, W O'Mullane, M Nieto-Santisteban, T Budavari, N Li, S Carliles, V Haridas, T Malik, and J Gray"
  Journal: "American Astronomical Society Meeting Abstracts"
  Volume: "205"
  Pages: "113.01"
  Description: "With the advent of digital archives and the VO, astronomy is quickly changing from a data-hungry to a data-intensive science. Local and specialized access to data will remain the most direct and efficient way to get data out of individual archives, especially if you know what you are looking for. However, the enormous sizes of the upcoming archives will preclude this type of access for most institutions, and will not allow researchers to tap the vast potential for discovery in cross-matching and comparing data between different archives. The VO makes this type of interoperability and distributed data access possible by adopting industry standards for data access (SQL) and data interchange (SOAP/XML) with platform independence (Web services)."
  bibAuthors: "Thakar, AR and Szalay, AS and O'Mullane, W and Nieto-Santisteban, M and Budavari, T and Li, N and Carliles, S and Haridas, V and Malik, T and Gray, J"
  Year: 2004
  Month: "December"
  Date: 20041200
  id: "publication-65"

- title: "Low lying spectroscopy of odd-odd"
  Authors: "T Bhattacharjee, D Banerjee, SK Das, S Chanda, T Malik, A Chowdhury, P Das, S Bhattacharyya, and R Guin"
  Journal: "arXiv preprint arXiv:1303.6398"
  Description: "Electron Capture (EC) decay of
          













          Gd(
          



















          = 48d) to the low lying states of
          













          Eu has been studied using high-resolution
          





          ray spectroscopy. The
          













          Gd activity was produced by (
          





          , 2n) reaction at E
          











          = 32 MeV using 93.8% enriched
          













          Sm target. The level structure has been considerably modified from the measurement of
          





          ray singles,
          







          coincidences and decay half lives. Lifetime measurement has been performed for the 3
          







          (114.06 keV) and 2
          







          (229.4 keV) levels of
          













          Eu using Mirror Symmetric Centroid Difference (MSCD) method with LaBr
          









          (Ce) detectors. The lifetimes for these two states have been found to be 5.38
          





          2.36 ps and 8.38
          





          2.19 ps respectively. Shell model calculation has been performed using OXBASH code in order to interpret the results."
  bibAuthors: "Bhattacharjee, T and Banerjee, D and Das, SK and Chanda, S and Malik, T and Chowdhury, A and Das, P and Bhattacharyya, S and Guin, R"
  Year: 2013
  Month: "March"
  Day: 26
  Date: 20130326
  id: "publication-66"

- title: "Using Provenance for Generating Automatic Citations"
  Authors: "Tanu Malik, Alexander Rasin, and Andrew Youngdahl"
  Conference: "10th USENIX Workshop on the Theory and Practice of Provenance (TaPP 2018)"
  Description: "When computational experiments include only datasets, they could be shared through the Uniform Resource Identifiers (URIs) or Digital Object Identifiers (DOIs) which point to these resources. However, experiments seldom include only datasets, but most often also include software, execution results, provenance, and other associated documentation. The Research Object has recently emerged as a comprehensive and systematic method for aggregation and identification of diverse elements of computational experiments. While an entire Research Object may be citable using a URI or a DOI, it is often desirable to cite specific sub-components of a research object to help identify, authorize, date, and retrieve the published sub-components of these objects. In this paper, we present an approach to automatically generate citations for sub-components of research objects by using the object's recorded provenance traces. The generated citations can be used as is or taken as suggestions that can be grouped and combined to produce higher level citations."
  bibAuthors: "Malik, Tanu and Rasin, Alexander and Youngdahl, Andrew"
  Year: 2018
  Date: 20180000
  id: "publication-67"

- title: "Using provenance for repeatability"
  Authors: "Quan Pham, Tanu Malik, and Ian Foster"
  Conference: "5th USENIX Workshop on the Theory and Practice of Provenance (TaPP 13)"
  Description: "We present Provenance-To-Use (PTU), a tool that minimizes computation time during repeatability testing. Authors can use PTU to build a package that includes their software program and a provenance trace of an initial reference execution. Testers can select a subset of the package’s processes for a partial deterministic replay—based, for example, on their compute, memory and I/O utilization as measured during the reference execution. Using the provenance trace, PTU guarantees that events are processed in the same order using the same data from one execution to the next. We show the efficiency of PTU for conducting repeatability testing of workflow-based scientific programs."
  bibAuthors: "Pham, Quan and Malik, Tanu and Foster, Ian"
  Year: 2013
  Date: 20130000
  id: "publication-68"

- title: "Middleware for managing provenance metadata"
  Authors: "Tanu Malik, Ligia Nistor, and Ashish Gehani"
  Book: "Middleware'10 Posters and Demos Track"
  Pages: "1-2"
  Description: "Current provenance collection systems typically gather metadata on remote hosts and submit it to a central server. We describe middleware for managing distributed provenance metadata, where each host maintains an authoritative local repository of the provenance metadata gathered on it. The approach provides several advantages---the system can scale to handle the large amounts of metadata generated when auditing occurs at fine granularity; users retain control over their provenance records; and the middleware transparently queries remote provenance stores to reconstruct distributed lineage."
  bibAuthors: "Malik, Tanu and Nistor, Ligia and Gehani, Ashish"
  Year: 2010
  Month: "November"
  Day: 29
  Date: 20101129
  id: "publication-69"

- title: "Sciunits: Reusable Research Objects"
  Authors: "Gabriel Fils, Zhihao Yuan, and Tanu Malik"
  Conference: "2017 IEEE 13th International Conference on e-Science (e-Science)"
  Pages: "374-383"
  Publisher: "IEEE"
  Description: "Science is conducted collaboratively, often requiring knowledge sharing about computational experiments. When experiments include only datasets, they can be shared using Uniform Resource Identifiers (URIs) or Digital Object Identifiers (DOIs). An experiment, however, seldom includes only datasets, but more often includes software, its past execution, provenance, and associated documentation. The Research Object has recently emerged as a comprehensive and systematic method for aggregation and identification of diverse elements of computational experiments. While a necessary method, mere aggregation is not sufficient for the sharing of computational experiments. Other users must be able to easily recompute on these shared research objects. In this paper, we present the sciunit, a reusable research object in which aggregated content is recomputable. We describe a Git-like client that efficiently creates …"
  bibAuthors: "Fils, Gabriel and Yuan, Zhihao and Malik, Tanu"
  Year: 2017
  Month: "October"
  Day: 24
  Date: 20171024
  id: "publication-70"

- title: "Lifetime measurement with LaBr3 (Ce) Detector"
  Authors: "D Banerjee, A Saha, T Malik, T Bhattacharjee, SR Banerjee, and SK Das"
  Journal: "Proceedings of the DAE Symp. on Nucl. Phys"
  Volume: "58"
  Pages: "890"
  Description: "LaBr3 (Ce) detector, known as BrilLanCe 380, is the best scintillator available till date for the applications related to gamma ray spectroscopy [1]. Very high light output (~ 63000 photons/MeV) and a low decay time (~ 20 ns) make it superior even compared to germanium detectors in several applications [2, 3]. The detector has been used to measure the nuclear level lifetimes from ns down to few ps [4, 5]. The measurement based on Perturbed Angular Correlation Technique has also been benefitted by the improved time and energy resolution of this detector [6]. This has been very important achievement specifically for the nuclear structure studies as the measurement of level lifetime and transition moments gives a direct insight into the structure of a particular nucleus. The selection of a photomultiplier tube with a reasonable gain and transit time is a very crucial parameter for a meaningful timing measurement with this detector. The XP2020/URQ is one such widely used photomultiplier which has been used in our measurement at an operating bias voltage of 2500 Volts [7]. The timing information is generally extracted by slope method when the lifetimes are of the order of few or tens of ns. The measurement of lifetimes of the order of few ps uses the Mirror Symmetric Centroid Difference (MSCD) technique which is only possible with a detector like LaBr3 (Ce)[4]. In order to study the performance of XP2020/URQ coupled LaBr3 (Ce), it is important to measure several known lifetimes of different ranges. The involved γ energy gate is one of the crucial factors in the success of timing spectroscopy. The γ-γ cascades with close lying transition energies …"
  bibAuthors: "Banerjee, D and Saha, A and Malik, T and Bhattacharjee, T and Banerjee, SR and Das, SK"
  Year: 2013
  Date: 20130000
  id: "publication-71"

- title: "Utilizing provenance in reusable research objects"
  Authors: "Zhihao Yuan, Dai Hai Ton That, Siddhant Kothari, Gabriel Fils, and Tanu Malik"
  Journal: "Informatics"
  Volume: "5"
  Issue: "1"
  Pages: "14"
  Publisher: "Multidisciplinary Digital Publishing Institute"
  Description: "Science is conducted collaboratively, often requiring the sharing of knowledge about computational experiments. When experiments include only datasets, they can be shared using Uniform Resource Identifiers (URIs) or Digital Object Identifiers (DOIs). An experiment, however, seldom includes only datasets, but more often includes software, its past execution, provenance, and associated documentation. The Research Object has recently emerged as a comprehensive and systematic method for aggregation and identification of diverse elements of computational experiments. While a necessary method, mere aggregation is not sufficient for the sharing of computational experiments. Other users must be able to easily recompute on these shared research objects. Computational provenance is often the key to enable such reuse. In this paper, we show how reusable research objects can utilize provenance to correctly repeat a previous reference execution, to construct a subset of a research object for partial reuse, and to reuse existing contents of a research object for modified reuse. We describe two methods to summarize provenance that aid in understanding the contents and past executions of a research object. The first method obtains a process-view by collapsing low-level system information, and the second method obtains a summary graph by grouping related nodes and edges with the goal to obtain a graph view similar to application workflow. Through detailed experiments, we show the efficacy and efficiency of our algorithms."
  bibAuthors: "Yuan, Zhihao and That, Dai H T T and Kothari, Siddhant and Fils, Gabriel and Malik, Tanu"
  Year: 2018
  Month: "March"
  Date: 20180300
  id: "publication-72"

- title: "FusionProv: Towards a Provenance-Aware Distributed Filesystem"
  Authors: "Chen Shou, Dongfang Zhao, Tanu Malik, and Ioan Raicu"
  Journal: "Greater Chicago Area System Research Workshop (GCASR)"
  Pages: "31"
  Description: "It has become increasingly important to capture and understand the origins and derivation of data (its provenance). A key issue in evaluating the feasibility of data provenance is its performance, overheads, and scalability. In this paper, we explore the feasibility of a management layer for parallel file systems, in which metadata includes both file operations and provenance metadata. We design and implement a provenance layer within a distributed file system—FusionFS, which implements a distributed file metadata management based on distributed hash tables. Our results show that FusionFS with its own storage layer for provenance capture is able to scale up to 1K nodes on BlueGene/P supercomputer."
  bibAuthors: "Shou, Chen and Zhao, Dongfang and Malik, Tanu and Raicu, Ioan"
  Year: 2013
  Date: 20130000
  id: "publication-73"

- title: "J. vandenBerg,“"
  Authors: "Alexander S Szalay, Jim Gray, Ani R Thakar, Peter Z Kunszt, Tanu Malik, Jordan Raddick, and Christopher Stoughton"
  Journal: "The sdss skyserver-public access to the sloan digital sky server data,” SIGMOD Conference"
  Pages: "570-581"
  bibAuthors: "Szalay, Alexander S S and Gray, Jim and Thakar, Ani R T and Kunszt, Peter Z K and Malik, Tanu and Raddick, Jordan and Stoughton, Christopher"
  Year: 2002
  Month: "August"
  Date: 20020800
  id: "publication-74"

- title: "{PROV-CRT}: Provenance Support for Container Runtimes"
  Authors: "Raza Ahmad, Yuta Nakamura, Naga Nithin Manne, and Tanu Malik"
  Conference: "12th International Workshop on Theory and Practice of Provenance (TaPP 2020)"
  Description: "A container runtime isolates computations and its associated data dependencies and is thus useful for porting applications on new machines. Current container runtimes, such as LXC and Docker, however, do not automatically track provenance, which is essential for verifying computations. We demonstrate PROV-CRT, a provenance module in a container runtime that tracks the provenance of computations during container creation and uses audited provenance to compare computations during container replay. We show how this module simplifies and improves the efficiency of complex container management tasks, such as classifying container contents and incrementally replaying containerized applications."
  bibAuthors: "Ahmad, Raza and Nakamura, Yuta and Manne, Naga N M and Malik, Tanu"
  Year: 2020
  Date: 20200000
  id: "publication-75"

- title: "On Lowering Merge Costs of an LSM Tree"
  Authors: "Mohammadsaleh Gharehdaghi, Alexander Rasin, and Tanu Malik"
  Issue: "6129"
  Publisher: "EasyChair"
  bibAuthors: "Gharehdaghi, Mohammadsaleh and Rasin, Alexander and Malik, Tanu"
  Year: 2021
  Month: "July"
  Day: 21
  Date: 20210721
  id: "publication-76"

- title: "Data Engineering"
  Authors: "Arnaud Sahuguet, John Krauss, Luis Palacios, David Sangokoya, Charlie Catlett, Tanu Malik, Brett Goldstein, Jonathan Giuffrida, Yetong Shao, Alessandro Panella, Derek Eder, Eric van Zanten, Robert Mitchum, Severin Thaler, Ian Foster, Juliana Freire, Cláudio Silva, Huy Vo, Harish Doraiswamy, Nivan Ferreira, and Jorge Poco"
  bibAuthors: "Sahuguet, Arnaud and Krauss, John and Palacios, Luis and Sangokoya, David and Catlett, Charlie and Malik, Tanu and Goldstein, Brett and Giuffrida, Jonathan and Shao, Yetong and Panella, Alessandro and Eder, Derek and Zanten, Eric v Z and Mitchum, Robert and Thaler, Severin and Foster, Ian and Freire, Juliana and Silva, Cláudio and Vo, Huy and Doraiswamy, Harish and Ferreira, Nivan and Poco, Jorge"
  id: "publication-77"

- title: "Providing scalable data services in ubiquitous networks"
  Authors: "Tanu Malik, Raghvendra Prasad, Sanket Patil, Amitabh Chaudhary, and Venkat Venkatasubramanian"
  Conference: "International Conference on Database Systems for Advanced Applications"
  Pages: "445-457"
  Publisher: "Springer, Berlin, Heidelberg"
  Description: "Topology is a fundamental part of a network that governs connectivity between nodes, the amount of data flow and the efficiency of data flow between nodes. In traditional networks, due to physical limitations, topology remains static for the course of the network operation. Ubiquitous data networks (UDNs), alternatively, are more adaptive and can be configured for changes in their topology. This flexibility in controlling their topology makes them very appealing and an attractive medium for supporting “anywhere, any place” communication. However, it raises the problem of designing a dynamic topology. The dynamic topology design problem is of particular interest to application service providers who need to provide cost-effective data services on a ubiquitous network. In this paper we describe algorithms that decide when and how the topology should be reconfigured in response to a change in the data …"
  bibAuthors: "Malik, Tanu and Prasad, Raghvendra and Patil, Sanket and Chaudhary, Amitabh and Venkatasubramanian, Venkat"
  Year: 2010
  Month: "April"
  Day: 1
  Date: 20100401
  id: "publication-78"

- title: "CINERGI: Community Inventory of EarthCube Resources for Geoscience Interoperability"
  Authors: "Ilya Zaslavsky, Luis Bermudez, Jeffrey Grethe, Amarnath Gupta, Leslie Hsu, Kerstin Lehnert, Tanu Malik, Stephen Richard, David Valentine, and Thomas Whitenack"
  Journal: "EGU General Assembly Conference Abstracts"
  Pages: "4792"
  Description: "Organizing geoscience data resources to support cross-disciplinary data discovery, interpretation, analysis and integration is challenging because of different information models, semantic frameworks, metadata profiles, catalogs, and services used in different geoscience domains, not to mention different research paradigms and methodologies. The central goal of CINERGI, a new project supported by the US National Science Foundation through its EarthCube Building Blocks program, is to create a methodology and assemble a large inventory of high-quality information resources capable of supporting data discovery needs of researchers in a wide range of geoscience domains. The key characteristics of the inventory are: 1) collaboration with and integration of metadata resources from a number of large data facilities; 2) reliance on international metadata and catalog service standards; 3) assessment of resource …"
  bibAuthors: "Zaslavsky, Ilya and Bermudez, Luis and Grethe, Jeffrey and Gupta, Amarnath and Hsu, Leslie and Lehnert, Kerstin and Malik, Tanu and Richard, Stephen and Valentine, David and Whitenack, Thomas"
  Year: 2014
  Month: "May"
  Date: 20140500
  id: "publication-79"

- title: "SkyQuery-A prototype distributed query and cross-matching web service for the virtual observatory"
  Authors: "AR Thakar, T Budavari, T Malik, AS Szalay, G Fekete, M Nieto-Santisteban, V Haridas, and J Gray"
  Journal: "American Astronomical Society Meeting Abstracts"
  Volume: "201"
  Pages: "105.07"
  Description: "We have developed a prototype distributed query and cross-matching service for the VO community, called SkyQuery, which is implemented with hierarchichal Web Services. SkyQuery enables astronomers to run combined queries on existing distributed heterogeneous astronomy archives. SkyQuery provides a simple, user-friendly interface to run distributed queries over the federation of registered astronomical archives in the VO. The SkyQuery client connects to the portal Web Service, which farms the query out to the individual archives, which are also Web Services called SkyNodes. The cross-matching algorithm is run recursively on each SkyNode. Each archive is a relational DBMS with a HTM index for fast spatial lookups. The results of the distributed query are returned as an XML DataSet that is automatically rendered by the client. SkyQuery also returns the image cutout corresponding to the query result …"
  bibAuthors: "Thakar, AR and Budavari, T and Malik, T and Szalay, AS and Fekete, G and Nieto-Santisteban, M and Haridas, V and Gray, J"
  Year: 2002
  Month: "December"
  Date: 20021200
  id: "publication-80"

- title: "Where Provenance in Database Storage"
  Authors: "Alexander Rasin, Tanu Malik, James Wagner, and Caleb Kim"
  Conference: "International Provenance and Annotation Workshop"
  Pages: "231-235"
  Publisher: "Springer, Cham"
  Description: "Where
           
           provenance is a relationship between a data item and the location from which this data was copied. In a DBMS, a typical use of
           
            where
           
           provenance is in establishing a copy-by-address relationship between the output of a query and the particular data value(s) that originated it. Normal DBMS operations create a variety of auxiliary copies of the data (e.g., indexes, MVs, cached copies). These copies exist over time with relationships that evolve continuously – (A) indexes maintain the copy with a reference to the origin value, (B) MVs maintain the copy without a reference to the source table, (C) cached copies are created once and are never maintained. A query may be answered from any of these auxiliary copies; however, this
           
            where
           
           provenance is not computed or maintained. In this paper, we describe sources from which forensic analysis of storage can derive
           
            where
           
           provenance of table data. We also …"
  bibAuthors: "Rasin, Alexander and Malik, Tanu and Wagner, James and Kim, Caleb"
  Year: 2018
  Month: "July"
  Day: 9
  Date: 20180709
  id: "publication-81"

- title: "Sciunits: Reusable Research Objects"
  Authors: "Hai Ton Dai That, Gabriel Fils, Zhihao Yuan, and Tanu Malik"
  Journal: "arXiv e-prints"
  Pages: "arXiv: 1707.05731"
  Description: "Science is conducted collaboratively, often requiring knowledge sharing about computational experiments. When experiments include only datasets, they can be shared using Uniform Resource Identifiers (URIs) or Digital Object Identifiers (DOIs). An experiment, however, seldom includes only datasets, but more often includes software, its past execution, provenance, and associated documentation. The Research Object has recently emerged as a comprehensive and systematic method for aggregation and identification of diverse elements of computational experiments. While a necessary method, mere aggregation is not sufficient for the sharing of computational experiments. Other users must be able to easily recompute on these shared research objects. In this paper, we present the sciunit, a reusable research object in which aggregated content is recomputable. We describe a Git-like client that efficiently creates …"
  bibAuthors: "That, Hai T D T and Fils, Gabriel and Yuan, Zhihao and Malik, Tanu"
  Year: 2017
  Month: "July"
  Date: 20170700
  id: "publication-82"

- title: "Artifact Description/Artifact Evaluation: A Reproducibility Bane or a Boon"
  Authors: "Tanu Malik"
  Book: "Proceedings of the 4th International Workshop on Practical Reproducible Evaluation of Computer Systems"
  Pages: "1-1"
  Description: "Several systems research conferences now incorporate an artifact description and artifact evaluation (AD/AE) process as part of the paper submission. Authors of accepted papers optionally submit a plethora of artifacts: documentation, links, tools, code, data, and scripts for independent validation of the claims in their paper. An artifact evaluation committee (AEC) evaluates the artifacts and stamps papers with accepted artifacts, which then receive publisher badges. Does this AD/AE process serve authors and reviewers? Is it scalable for large conferences such as SCxy? Using the last three SCxy Reproducibility Initiatives as the basis, this talk will analyze the benefits and the miseries of the AD/AE process. Several systems research conferences now incorporate an artifact description and artifact evaluation (AD/AE) process as part of the paper submission. Authors of accepted papers optionally submit a plethora of …"
  bibAuthors: "Malik, Tanu"
  Year: 2021
  Month: "June"
  Day: 21
  Date: 20210621
  id: "publication-83"

- title: "Plenario: An Open Data Discovery and Exploration Platform for Urban Science."
  Authors: "Charlie Catlett, Tanu Malik, Brett Goldstein, Jonathan Giuffrida, Yetong Shao, Alessandro Panella, Derek Eder, Eric van Zanten, Robert Mitchum, Severin Thaler, and Ian T Foster"
  Journal: "IEEE Data Eng. Bull."
  Volume: "37"
  Issue: "4"
  Pages: "27-42"
  Description: "The past decade has seen the widespread release of open data concerning city services, conditions, and activities by government bodies and public institutions of all sizes. Hundreds of open data portals now host thousands of datasets of many different types. These new data sources represent enormous potential for improved understanding of urban dynamics and processes—and, ultimately, for more livable, efficient, and prosperous communities. However, those who seek to realize this potential quickly discover that discovering and applying those data relevant to any particular question can be extraordinarily difficult, due to decentralized storage, heterogeneous formats, and poor documentation. In this context, we introduce Plenario, a platform designed to automating time-consuming tasks associated with the discovery, exploration, and application of open city data—and, in so doing, reduce barriers to data use for researchers, policymakers, service providers, journalists, and members of the general public. Key innovations include a geospatial data warehouse that allows data from many sources to be registered into a common spatial and temporal frame; simple and intuitive interfaces that permit rapid discovery and exploration of data subsets pertaining to a particular area and time, regardless of type and source; easy export of such data subsets for further analysis; a user-configurable data ingest framework for automated importing and periodic updating of new datasets into the data warehouse; cloud hosting for elastic scaling and rapid creation of new Plenario instances; and an open source implementation to enable community contributions …"
  bibAuthors: "Catlett, Charlie and Malik, Tanu and Goldstein, Brett and Giuffrida, Jonathan and Shao, Yetong and Panella, Alessandro and Eder, Derek and Zanten, Eric v Z and Mitchum, Robert and Thaler, Severin and Foster, Ian T F"
  Year: 2014
  Month: "December"
  Day: 1
  Date: 20141201
  id: "publication-84"

- title: "Challenges with Maintaining Legacy Software to Achieve Reproducible Computational Analyses: An Example for Hydrologic Modeling Data Processing Pipelines"
  Authors: "Bakinam T Essawy, Jonathan L Goodall, Tanu Malik, Hao Xu, Michael Conway, and Yolanda Gil"
  Description: "In hydrology, like many other scientific disciplines with large computational demands, scientists have created a significant and growing collection of software tools for data manipulation, analysis, and simulation. While core computation model software are likely to be well maintained by the groups that develop these codes, other software such as data pre-and post-processing tools, used less often but still critical to scientists, may receive less attention. These codes will become “legacy” software, simply meaning that the software is out of date by modern standards. A challenge facing the scientific community is how to maintain this legacy software so that it achieves reproducible results now and in the future, with minimal investment of resources. This talk will present an example of this problem in hydrology with the pre-processing tools used to create a Variable Infiltration Capacity (VIC) model simulation. The data processing pipeline for creating the input files for VIC is complex requiring code written over the years by various student researchers and sometimes requiring out-of-date compilers (eg, FORTRAN 77) to compile portions of the code. We are confident that the use of legacy software is not a unique problem for VIC, but rather a wider problem common with other hydrologic models and scientific modeling in general. Through prior work, we have automated a VIC data processing pipeline, but moving these pipelines to new machines remains a significant challenge due in large part to the need to install legacy software dependencies. This work takes the following steps to address these challenges. The first step is to create containers using …"
  bibAuthors: "Essawy, Bakinam T E and Goodall, Jonathan L G and Malik, Tanu and Xu, Hao and Conway, Michael and Gil, Yolanda"
  Year: 2016
  Date: 20160000
  id: "publication-85"

- title: "Database forensic analysis with DBCarver"
  Authors: "James Wagner, Alexander Rasin, Tanu Malik, Karen Heart, Hugo Jehle, and Jonathan Grier"
  Journal: "CIDR 2017, 8th Biennial Conference on Innovative Data Systems Research"
  Description: "The increasing use of databases in the storage of critical and sensitive information in many organizations has lead to an increase in the rate at which databases are exploited in computer crimes. While there are several techniques and tools available for database forensics, they mostly assume apriori database preparation, such as relying on tamper-detection software to be in place or use of detailed logging. Investigators, alternatively, need forensic tools and techniques that work on poorly-configured databases and make no assumptions about the extent of damage in a database. In this paper, we present DBCarver, a tool for reconstructing database content from a database image without using any log or system metadata. The tool uses page carving to reconstruct both query-able data and non-queryable data (deleted data). We describe how the two kinds of data can be combined to enable a variety of forensic analysis questions hitherto unavailable to forensic investigators. We show the generality and efficiency of our tool across several databases through a set of robust experiments."
  bibAuthors: "Wagner, James and Rasin, Alexander and Malik, Tanu and Heart, Karen and Jehle, Hugo and Grier, Jonathan"
  Year: 2017
  Month: "January"
  Date: 20170100
  id: "publication-86"

- title: "RNEDE: Resilient network design environment"
  Authors: "Venkat Venkatasubramanian, Tanu Malik, Arun Giridhar, Kris Villez, Raghvendra Prasad, Aviral Shukla, Craig Rieger, Keith Daum, and Miles McQueen"
  Conference: "2010 3rd International Symposium on Resilient Control Systems"
  Pages: "72-75"
  Publisher: "IEEE"
  Description: "Modern living is more and more dependent on the intricate web of critical infrastructure systems. The failure or damage of such systems can cause huge disruptions. Traditional design of this web of critical infrastructure systems was based on the principles of functionality and reliability. However, it is increasingly being realized that such design objectives are not sufficient. Threats, disruptions and faults often compromise the network, taking away the benefits of an efficient and reliable design. Thus, traditional network design parameters must be combined with self-healing mechanisms to obtain a resilient design of the network. In this paper, we present RNEDE a resilient network design environment that not only optimizes the network for performance but tolerates fluctuations in its structure that result from external threats and disruptions. The environment evaluates a set of remedial actions to bring a compromised …"
  bibAuthors: "Venkatasubramanian, Venkat and Malik, Tanu and Giridhar, Arun and Villez, Kris and Prasad, Raghvendra and Shukla, Aviral and Rieger, Craig and Daum, Keith and McQueen, Miles"
  Year: 2010
  Month: "August"
  Day: 10
  Date: 20100810
  id: "publication-87"

- title: "SOLE: Linking Research Papers with Science Objects"
  Authors: "Tanu Malik, Quan Pham, and Ian Foster"
  Description: "• Dataset description: The Burnham Center for Chemical Genomics (BCCG) has launched a screen-‐ing campaign for aqueous solubility against the NIH Molecular Libraries Small Molecule Repository (MLSMR), which contains more than 350000 compounds. The resultant bioassay (PubChem AID: 1996) was deposited publicly in the PubChem BioAssay database.(31) As of June 18, 2010, this bioassay stored experimental solubility data for 47567 compounds. The solubility data can be downloaded from the PubChem FTP site (ftp://ftp. ncbi. nlm. nih. gov/pubchem/Bioassay/). All compounds were measured using a standard protocol under the same conditions.(32) We consider that data set compiled from a single source, eg, those used in this work, is more advantageous for statistical studies than those compiled from various sources(Supporting Information, Table S1).
          

           • Dataset description: The NCI-‐60 data set contains anticancer screening results for more than 40,000 compounds. It is publicly available in the PubChem BioAssay database (38) as 73 bioassays with the name of NCI human tumor cell line growth inhibition assay under the DTP/NCI data source. In this work, only the top 60 bioassays(referred hereafter as NCI-‐60) with the largest number of tested compounds were selected (Supporting Information, Table S1). Relevant bioactivity data were downloaded at the PubChem FTP site (ftp://ftp. ncbi. nlm. nih. gov/pubchem/Bioassay, accessed on December 9, 2010). A total of 5083 compounds were found commonly tested in all of the 60 bioassays. Additional data set characteristics are summarized in Supporting Information."
  bibAuthors: "Malik, Tanu and Pham, Quan and Foster, Ian"
  id: "publication-88"

- title: "On Lowering Merge Costs of an LSM Tree"
  Authors: "Mohammadsaleh Gharehdaghi Dai Hai Ton That, Alexander Rasin, and Tanu Malik"
  Description: "In column stores, which ingest large amounts of data into multiple column groups, query performance deteriorates. Commercial column stores use log-structured merge (LSM) tree on projections to ingest data rapidly. LSM tree improves ingestion performance, but for column stores the sort-merge maintenance phase in an LSM tree is I/O-intensive, which slows concurrent queries and reduces overall throughput. In this paper, we present a simple heuristic approach to reduce the sorting and merging cost that arise when data is ingested in column stores. We demonstrate how a Min-Max heuristic can construct buckets and identify the level of sortedness in each range of data. Filled and relatively-sorted buckets are written out to disk; unfilled buckets are retained to achieve a better level of sortedness, thus avoiding the expensive sort-merge phase. We compare our Min-Max approach with LSM tree and production columnar stores using real and synthetic datasets."
  bibAuthors: "That, Mohammadsaleh G D H T T and Rasin, Alexander and Malik, Tanu"
  Year: 2021
  Month: "July"
  Day: 21
  Date: 20210721
  id: "publication-89"

- title: "Measuring Researcher Diversity and its Impact on Grant Money"
  Authors: "Tanu Malik, Andrey Rzhetsky, and Ian Foster"
  Description: "Recent evidence has pointed out that an individual pays a positive cost in terms of quality when focusing on a broad range of topics. In this paper, we corroborate if scientific researchers also pay a cost in terms of grant money received. For this we measure researcher diversity and correlate it with the amount of money that a researcher has received from federal agencies over the years. Our results reconfirm the negative correlation between wide interests and quality but, on the contrary, indicate that to receive a funded grant it pays to have wide interests."
  bibAuthors: "Malik, Tanu and Rzhetsky, Andrey and Foster, Ian"
  id: "publication-90"

- title: "Pli: Augmenting live databases with custom clustered indexes"
  Authors: "James Wagner, Alexander Rasin, Dai Hai Ton That, and Tanu Malik"
  Book: "Proceedings of the 29th International Conference on Scientific and Statistical Database Management"
  Pages: "1-6"
  Description: "RDBMSes only support one clustered index per database table that can speed up query processing. Database applications, that continually ingest large amounts of data, perceive slow query response times to long downtimes, as the clustered index ordering must be strictly maintained. In this paper, we show that application slowdown or downtime, however, can often be avoided if database systems expose the physical location of attributes that are completely or approximately clustered."
  bibAuthors: "Wagner, James and Rasin, Alexander and That, Dai H T T and Malik, Tanu"
  Year: 2017
  Month: "June"
  Day: 27
  Date: 20170627
  id: "publication-91"

- title: "SkyQuery: A WebService approach to federate databases"
  Authors: "Tanu Malik, Alex S Szalay, Tamas Budavari, and Ani R Thakar"
  Journal: "arXiv preprint cs/0211023"
  Description: "Traditional science searched for new objects and phenomena that led to discoveries. Tomorrow's science will combine together the large pool of information in scientific archives and make discoveries. Scienthists are currently keen to federate together the existing scientific databases. The major challenge in building a federation of these autonomous and heterogeneous databases is system integration. Ineffective integration will result in defunct federations and under utilized scientific data. Astronomy, in particular, has many autonomous archives spread over the Internet. It is now seeking to federate these, with minimal effort, into a Virtual Observatory that will solve complex distributed computing tasks such as answering federated spatial join queries. In this paper, we present SkyQuery, a successful prototype of an evolving federation of astronomy archives. It interoperates using the emerging Web services standard. We describe the SkyQuery architecture and show how it efficiently evaluates a probabilistic federated spatial join query."
  bibAuthors: "Malik, Tanu and Szalay, Alex S S and Budavari, Tamas and Thakar, Ani R T"
  Year: 2002
  Month: "November"
  Day: 20
  Date: 20021120
  id: "publication-92"

- title: "Special issue on Data-driven Science"
  Authors: "Tanu Malik"
  Journal: "Distributed and Parallel Databases"
  Volume: "39"
  Issue: "2"
  Pages: "413-413"
  Publisher: "Springer US"
  Description: "Big Data issues and challenges affect any scientific enterprise. Traditionally, most enterprises have addressed the big data issues of volume, velocity, and variety in isolation; with the advent of low-cost sensors and edge computing, the scientific enterprise must increasingly address these issues in combination. This special issue on data-driven science explores the issues of data volume, data variety, and data velocity through a single lens. It puts forward novel dynamic and analytic methods for some classical problems in scientific data management such as dependency estimation, constructing wavelet synopses, and schema evolution. The issue advances the state of statistical and scientific database management by providing data-driven guidance for knowledge discovery and analytics. We present three papers on the topic of data-driven science. In “A Framework for Dependency Estimation in Heterogeneous …"
  bibAuthors: "Malik, Tanu"
  Year: 2021
  Month: "June"
  Date: 20210600
  id: "publication-93"

- title: "Documenting computing environments for reproducible experiments"
  Authors: "Jason Chuah, Madeline Deeds, Tanu Malik, Youngdon Choi, and Jonathan L Goodall"
  Book: "Parallel Computing: Technology Trends"
  Pages: "756-765"
  Publisher: "IOS Press"
  Description: "Establishing the reproducibility of an experiment often requires repeating the experiment in its native computing environment. Containerization tools provide declarative interfaces for documenting native computing environments. Declarative documentation, however, may not precisely recreate the native computing environment because of human errors or dependency conflicts. An alternative is to trace the native computing environment during application execution. Tracing, however, does not generate declarative documentation."
  bibAuthors: "Chuah, Jason and Deeds, Madeline and Malik, Tanu and Choi, Youngdon and Goodall, Jonathan L G"
  Year: 2020
  Date: 20200000
  id: "publication-94"

- title: "Towards a Conceptual Design of a Cross-Domain Integrative Information System for the Geosciences"
  Authors: "I Zaslavsky, SM Richard, DW Valentine, T Malik, and A Gupta"
  Journal: "AGU Fall Meeting Abstracts"
  Volume: "2013"
  Pages: "IN43B-04"
  Description: "As geoscientists increasingly focus on studying processes that span multiple research domains, there is an increased need for cross-domain interoperability solutions that can scale to the entire geosciences, bridging information and knowledge systems, models, software tools, as well as connecting researchers and organization. Creating a community-driven cyberinfrastructure (CI) to address the grand challenges of integrative Earth science research and education is the focus of EarthCube, a new research initiative of the US National Science Foundation. We are approaching EarthCube design as a complex socio-technical system of systems, in which communication between various domain subsystems, people and organizations enables more comprehensive, data-intensive research designs and knowledge sharing. In particular, we focus on integrating'traditional'layered CI components-including information …"
  bibAuthors: "Zaslavsky, I and Richard, SM and Valentine, DW and Malik, T and Gupta, A"
  Year: 2013
  Month: "December"
  Date: 20131200
  id: "publication-95"

- title: "Making Database Applications Shareable"
  Authors: "Boris Glavic, Tanu Malik, and Quan Pham"
  Publisher: "TAPP"
  Description: "Motivation. Sharing and repeating applications that involve interactions with a database is currently a painful and cumbersome process. In this poster we discuss how to make sharing such applications trivial through the combination of three techniques and systems we have recently developed: LDV (Light-weight database virtualization)[1] is a tool for sharing and repeating applications accessing a relational database. LDV monitors the execution of an application including its database access and creates a reproducibility package that can be shared and reexecuted on a different machine. In addition to a provenance graph, such a package contains all dependencies of the application (libraries, binaries, and data files) and the relevant slice of the database required for reexecution. Running a packaged application requires neither any manual installation nor setting up a database. We use LDV as a client application for creating provenance graphs and packaging applications and as a tool for reexecuting packages. GProM (Generic Provenance Middleware)[2] is a database independent provenance middleware for computing provenance of queries, updates, and transactions over multiple database backends. We use GProM to compute fine-grained provenance for SQL commands to determine what data needs to be included in a repeatability package. That is, GProM is integrated with LDV to wrap the database interfaces used by an application. PROVaaS (http://provaas. org/) is a web platform (RESTful service) for storing and querying provenance documents. Clients can upload provenance described in PROV (http://www. w3. org/TR/prov …"
  bibAuthors: "Glavic, Boris and Malik, Tanu and Pham, Quan"
  Year: 2015
  Date: 20150000
  id: "publication-96"

- title: "Open SkyQuery--VO Compliant Dynamic Federation of Astronomical Archives"
  Authors: "Tamás Budavári, AS Szalay, J Gray, W O'Mullane, R Williams, A Thakar, T Malik, N Yasuda, and R Mann"
  Conference: "Astronomical Data Analysis Software and Systems (ADASS) XIII"
  Volume: "314"
  Pages: "177"
  Description: "We discuss the redesign of the SkyQuery architecture, originally built as a simple proof of concept for dynamic federation of astronomical archives. In keeping with the Virtual Observatory philosophy of"
  bibAuthors: "Budavári, Tamás and Szalay, AS and Gray, J and O'Mullane, W and Williams, R and Thakar, A and Malik, T and Yasuda, N and Mann, R"
  Year: 2004
  Month: "July"
  Date: 20040700
  id: "publication-97"

- title: "DF-toolkit: interacting with low-level database storage"
  Authors: "James Wagner, Alexander Rasin, Karen Heart, Tanu Malik, and Jonathan Grier"
  Journal: "Proceedings of the VLDB Endowment"
  Volume: "13"
  Issue: "12"
  Description: "Applications in several areas, such as privacy, security, and integrity validation, require direct access to database management system (DBMS) storage. However, relational DBM-Ses are designed for physical data independence, and thus limit internal storage exposure. Consequently, applications either cannot be enabled or access storage with ad-hoc solutions, such as querying the ROWID (which can expose physical record location within DBMS storage but not within OS storage) or using DBMS “page repair” tools that read and write DBMS data pages directly. Such ad-hoc methods are limited in their capabilities and difficult to program, maintain, and port across various DBMSes. In this demonstration, we showcase DF-Toolkit–a set of tools that provide an abstracted access to the DBMS storage layer. Users will be able to view DBMS storage not accessible through other applications. Examples include unallocated (eg, deleted) data, index value-pointer pairs, and cached DBMS pages in RAM. Users will also be able to interact with several special-purpose security applications that audit DBMS storage beyond what DBMS vendors support."
  bibAuthors: "Wagner, James and Rasin, Alexander and Heart, Karen and Malik, Tanu and Grier, Jonathan"
  Year: 2020
  Month: "August"
  Date: 20200800
  id: "publication-98"

- title: "ODSA: Op enDatabase Sto rage Access James Wagner"
  Authors: "Alexander Rasin, Tanu Malik, and Jonathan Grier"
  Description: "Applications in several areas, such as privacy, security, and integrity validation, require direct access to database management system (DBMS) storage. However, relational DBMSes are designed for physical data independence, and thus limit internal storage exposure. Consequently, applications either cannot be enabled or access storage with ad-hoc solutions, such as querying the ROWID (thereby exposing physical record location within DBMS storage but not OS storage) or using DBMS “page repair” tools that read and write DBMS data pages directly. These ad-hoc methods are difficult to program, maintain, and port across various DBMSes.
          

           In this paper, we present a specification of programmable access to relational DBMS storage. Open Database Storage Access (ODSA) is a simple, DBMS-agnostic, easy-to-program storage interface for DBMSes. We formulate novel operations using ODSA, such as comparing page-level metadata. We present three compelling use cases that are enabled by ODSA and demonstrate how to implement them with ODSA."
  bibAuthors: "Rasin, Alexander and Malik, Tanu and Grier, Jonathan"
  id: "publication-99"

- title: "Plenario: A Spatio-Temporal Platform for Discovery and Exploration of Urban Science Data"
  Authors: "WH Engler, T Malik, C Catlett, I Foster, and B Goldstein"
  Journal: "AGU Fall Meeting Abstracts"
  Volume: "2015"
  Pages: "IN51A-1800"
  Description: "The past decade has seen the widespread release of open data concerning city services, conditions, and activities by government bodies and public institutions of all sizes. Hundreds of open data portals now host thousands of datasets of many different types. These new data sources represent enormous potential for improved understanding of urban dynamics and processes—and, ultimately, for more livable, efficient, and prosperous communities. However, those who seek to realize this potential quickly discover that discovering and applying those data relevant to any particular question can be extraordinarily difficult, due to decentralized storage, heterogeneous formats, and poor documentation. In this context, we introduce Plenario, a platform designed to automating time-consuming tasks associated with the discovery, exploration, and application of open city data—and, in so doing, reduce barriers to data use …"
  bibAuthors: "Engler, WH and Malik, T and Catlett, C and Foster, I and Goldstein, B"
  Year: 2015
  Month: "December"
  Date: 20151200
  id: "publication-100"

- title: "Personalized, Shareable Geoscience Dataspaces For Simplifying Data Management and Improving Reproducibility"
  Authors: "Tanu Malik, Ian Foster, Jonathan L Goodall, Scott Dale Peckham, Joseph BH Baker, and Michael Gurnis"
  Journal: "AGU Fall Meeting Abstracts"
  Volume: "2015"
  Pages: "IN21E-01"
  Description: "Research activities are iterative, collaborative, and now data-and compute-intensive. Such research activities mean that even the many researchers who work in small laboratories must often create, acquire, manage, and manipulate much diverse data and keep track of complex software. They face difficult data and software management challenges, and data sharing and reproducibility are neglected. There is signficant federal investment in powerful cyberinfrastructure, in part to lesson the burden associated with modern data-and compute-intensive research. Similarly, geoscience communities are establishing research repositories to facilitate data preservation. Yet we observe a large fraction of the geoscience community continues to struggle with data and software management. The reason, studies suggest, is not lack of awareness but rather that tools do not adequately support time-consuming data life cycle …"
  bibAuthors: "Malik, Tanu and Foster, Ian and Goodall, Jonathan L G and Peckham, Scott D P and Baker, Joseph B B and Gurnis, Michael"
  Year: 2015
  Month: "December"
  Date: 20151200
  id: "publication-101"

- title: "A dynamic data middleware cache for rapidly-growing scientific repositories"
  Authors: "Tanu Malik, Xiaodan Wang, Philip Little, Amitabh Chaudhary, and Ani Thakar"
  Conference: "ACM/IFIP/USENIX International Conference on Distributed Systems Platforms and Open Distributed Processing"
  Pages: "64-84"
  Publisher: "Springer, Berlin, Heidelberg"
  Description: "Modern scientific repositories are growing rapidly in size. Scientists are increasingly interested in viewing the latest data as part of query results. Current scientific middleware cache systems, however, assume repositories are static. Thus, they cannot answer scientific queries with the latest data. The queries, instead, are routed to the repository until data at the cache is refreshed. In data-intensive scientific disciplines, such as astronomy, indiscriminate query routing or data refreshing often results in runaway network costs. This severely affects the performance and scalability of the repositories and makes poor use of the cache system. We present
           
            Delta
           
           a dynamic data middleware cache system for rapidly-growing scientific repositories.
           
            Delta
           
           ’s key component is a decision framework that adaptively
           
            decouples
           
           data objects—choosing to keep some data object at the cache, when they are heavily queried, and …"
  bibAuthors: "Malik, Tanu and Wang, Xiaodan and Little, Philip and Chaudhary, Amitabh and Thakar, Ani"
  Year: 2010
  Month: "November"
  Day: 29
  Date: 20101129
  id: "publication-102"

- title: "A Dynamic Data Middleware System for Rapidly-growing Scientific Repositories"
  Authors: "Tanu Malik, Xiaodan Wang, Philip Little, Amitabh Chaudhary, and Ani Thakar"
  Description: "Modern scientific repositories are growing rapidly in size. Scientists are increasingly interested in viewing the latest data as part of query results. Current scientific middleware systems, however, assume repositories are static. Thus, they cannot answer scientific queries with the latest data. The queries, instead, are routed to the repository until data at the middleware system is refreshed. In data-intensive scientific disciplines, such as astronomy, indiscriminate query routing or data refreshing often results in runaway network costs. This severely affects the performance and scalability of the repositories and makes poor use of the middleware system. We present Delta a dynamic data middleware system for rapidly-growing scientific repositories. Delta’s key component is a decision framework that adaptively decouples data objects—choosing to keep some data object at the middleware, when they are heavily queried, and keeping some data objects at the repository, when they are heavily updated. Our algorithm profiles incoming workload to search for optimal data decoupling that reduces network costs. It leverages formal concepts from the network flow problem, and is robust to evolving scientific workloads. We evaluate the efficacy of Delta, through a prototype implementation, by running query traces collected from a real astronomy survey."
  bibAuthors: "Malik, Tanu and Wang, Xiaodan and Little, Philip and Chaudhary, Amitabh and Thakar, Ani"
  id: "publication-103"

- title: "GeoDataspaces: Simplifying Data Management Tasks with Globus"
  Authors: "Tanu Malik, Kyle Chard, Roselyne B Tchoua, and Ian Foster"
  Journal: "AGU Fall Meeting Abstracts"
  Volume: "2014"
  Pages: "IN34B-08"
  Description: "Data and its management are central to modern scientific enterprise. Typically, geoscientists rely on observations and model output data from several disparate sources (file systems, RDBMS, spreadsheets, remote data sources). Integrated data management solutions that provide intuitive semantics and uniform interfaces, irrespective of the kind of data source are, however, lacking. Consequently, geoscientists are left to conduct low-level and time-consuming data management tasks, individually, and repeatedly for discovering each data source, often resulting in errors in handling. In this talk we will describe how the EarthCube GeoDataspace project is improving this situation for seismologists, hydrologists, and space scientists by simplifying some of the existing data management tasks that arise when developing computational models. We will demonstrate a GeoDataspace, bootstrapped with geounits, which are …"
  bibAuthors: "Malik, Tanu and Chard, Kyle and Tchoua, Roselyne B T and Foster, Ian"
  Year: 2014
  Month: "December"
  Date: 20141200
  id: "publication-104"

- title: "PDACS: a portal for data analysis services for cosmological simulations"
  Authors: "Ravi Madduri, Alex Rodriguez, Thomas Uram, Katrin Heitmann, Tanu Malik, Saba Sehrish, Ryan Chard, Shreyas Cholia, Marc Paterno, Jim Kowalkowski, and Salman Habib"
  Journal: "Computing in Science & Engineering"
  Volume: "17"
  Issue: "5"
  Pages: "18-26"
  Publisher: "IEEE"
  Description: "PDACS (Portal for Data Analysis Services for Cosmological Simulations) is a Web-based analysis portal that provides access to large simulations and large-scale parallel analysis tools to the research community. It provides opportunities to access, transfer, manipulate, search, and record simulation data, as well as to contribute applications and carry out (possibly complex) computational analyses of the data. PDACS also enables wrapping of analysis tools written in a large number of languages within its workflow system, providing a powerful way to carry out multilevel/multistep analyses. The system allows for cross-layer provenance tracking, implementing a transparent method for sharing workflow specifications, as well as a convenient mechanism for checking reproducibility of results generated by the workflows. Users are able to submit their own tools to the system and to share tools with the rest of the community."
  bibAuthors: "Madduri, Ravi and Rodriguez, Alex and Uram, Thomas and Heitmann, Katrin and Malik, Tanu and Sehrish, Saba and Chard, Ryan and Cholia, Shreyas and Paterno, Marc and Kowalkowski, Jim and Habib, Salman"
  Year: 2015
  Month: "July"
  Day: 13
  Date: 20150713
  id: "publication-105"

- title: "CHEX: Multiversion Replay with Ordered Checkpoints"
  Authors: "Naga Nithin Manne, Shilvi Satpati, Tanu Malik, Amitabha Bagchi, Ashish Gehani, and Amitabh Chaudhary"
  Journal: "arXiv e-prints"
  Pages: "arXiv: 2202.08429"
  Description: "In scientific computing and data science disciplines, it is often necessary to share application workflows and repeat results. Current tools containerize application workflows, and share the resulting container for repeating results. These tools, due to containerization, do improve sharing of results. However, they do not improve the efficiency of replay. In this paper, we present the multiversion replay problem which arises when multiple versions of an application are containerized, and each version must be replayed to repeat results. To avoid executing each version separately, we develop CHEX, which checkpoints program state and determines when it is permissible to reuse program state across versions. It does so using system call-based execution lineage. Our capability to identify common computations across versions enables us to consider optimizing replay using an in-memory cache, based on a checkpoint …"
  bibAuthors: "Manne, Naga N M and Satpati, Shilvi and Malik, Tanu and Bagchi, Amitabha and Gehani, Ashish and Chaudhary, Amitabh"
  Year: 2022
  Month: "February"
  Date: 20220200
  id: "publication-106"

- title: "Hashmi, Jahanzeb Maqbool 111 He, Pan 51 Hughey, Stephen 41 Hundt, Christian 11"
  Authors: "Aleksandar Ilic, Grey Ballard, Dip Sankar Banerjee, Tania Banerjee, Leonardo Bautista-Gomez, H Alan Beadle, Olivier Beaumont, Michela Becchi, Cristiana Bentes, Ali R Butt, Wentao Cai, Jesus Carretero, Mohak Chadha, Deepak Chaudhary, Venkatesh Choppella, James Demmel, Aditya Devarakonda, Doga Dikbayir, Abdoulaye Diop, Nahid Emad, Lionel Eyraud-Dubois, Olaf Faaland, Guang Gao, Javier Garcia-Blas, Felix Garcia-Carballeira, Michael Gerndt, Hemant Kumar Giri, Elsa Gonsiorowski, Antonio González, Ruidong Gu, Rajiv Gupta, Mridul Haque, Chirayu Anant Haryan, Xiaolin Jiang, Jophin John, Lizy K John, Daniel Jünger, Rajgopal Kannan, Ramakrishnan Kannan, Anuradha Kanukotla, Kai Keller, Thomas Keller, Robin Kobus, Vivek Kumar, Jing Li, Ruihao Li, Michael Lingg, Weiguo Liu, Tanu Malik, Lawton Manning, Joseph Manzano, Andres Marquez, Abbas Mazloumi, Henning Meyerhenke, Kathryn Mohror, Adam Moody, André Müller, Narendra Mutyala, Yuta Nakamura, Rupesh Nasre, Pavan Nittur, Surya Teja Palavalasa, Dhabaleswar K Panda, and Akshay Parashar"
  Description: "Presents an index of the authors whose articles are published in the conference proceedings record."
  bibAuthors: "Ilic, Aleksandar and Ballard, Grey and Banerjee, Dip S B and Banerjee, Tania and Bautista-Gomez, Leonardo and Beadle, H A B and Beaumont, Olivier and Becchi, Michela and Bentes, Cristiana and Butt, Ali R B and Cai, Wentao and Carretero, Jesus and Chadha, Mohak and Chaudhary, Deepak and Choppella, Venkatesh and Demmel, James and Devarakonda, Aditya and Dikbayir, Doga and Diop, Abdoulaye and Emad, Nahid and Eyraud-Dubois, Lionel and Faaland, Olaf and Gao, Guang and Garcia-Blas, Javier and Garcia-Carballeira, Felix and Gerndt, Michael and Giri, Hemant K G and Gonsiorowski, Elsa and González, Antonio and Gu, Ruidong and Gupta, Rajiv and Haque, Mridul and Haryan, Chirayu A H and Jiang, Xiaolin and John, Jophin and John, Lizy K J and Jünger, Daniel and Kannan, Rajgopal and Kannan, Ramakrishnan and Kanukotla, Anuradha and Keller, Kai and Keller, Thomas and Kobus, Robin and Kumar, Vivek and Li, Jing and Li, Ruihao and Lingg, Michael and Liu, Weiguo and Malik, Tanu and Manning, Lawton and Manzano, Joseph and Marquez, Andres and Mazloumi, Abbas and Meyerhenke, Henning and Mohror, Kathryn and Moody, Adam and Müller, André and Mutyala, Narendra and Nakamura, Yuta and Nasre, Rupesh and Nittur, Pavan and Palavalasa, Surya T P and Panda, Dhabaleswar K P and Parashar, Akshay"
  id: "publication-107"

- title: "Lens: a faceted browser for research networking platforms"
  Authors: "Richard Whaling, Tanu Malik, and Ian Foster"
  Conference: "2013 IEEE 9th International Conference on e-Science"
  Pages: "196-203"
  Publisher: "IEEE"
  Description: "Research networking platforms, such as VIVO and Profiles Networking provide an information infrastructure for scholarship, representing information about research and researchers-their scholarly works, research interests, and organizational relationships. These platforms are open information infrastructures for scholarship, consisting of linked open data and open-source software tools for managing and visualizing scholarly information. Being RDF based, faceted browsing is a natural technique for navigating such data, partitioning the scholarly information space into orthogonal conceptual dimensions. However, this technique has so far been explored through limited queries in research networking platforms-not allowing for instance full graph based navigation on RDF data. In this paper we present Lens a client-side user interface for faceted navigation of scholarly RDF data. Lens is based on Exhibit, which is a …"
  bibAuthors: "Whaling, Richard and Malik, Tanu and Foster, Ian"
  Year: 2013
  Month: "October"
  Day: 22
  Date: 20131022
  id: "publication-108"

- title: "MiDas: Containerizing Data-Intensive Applications with I/O Specialization"
  Authors: "Chaitra Niddodi, Ashish Gehani, Tanu Malik, Jorge A Navas, and Sibin Mohan"
  Book: "Proceedings of the 3rd International Workshop on Practical Reproducible Evaluation of Computer Systems"
  Pages: "21-25"
  Description: "Scientific applications often depend on data produced from computational models. Model-generated data can be prohibitively large. Current mechanisms for sharing and distributing reproducible applications, such as containers, assume all model data is saved and included with a program to support its successful re-execution. However, including model data increases the sizes of containers. This increases the cost and time required for deployment and further reuse. We present a framework named MiDas ( Minimizing Datasets) for specializing I/O libraries which, given an application, automates the process of identifying and including only a subset of the data accessed by the program. To do this, MiDas combines static and dynamic analysis techniques to map high level user inputs to low level file offsets. We show several orders of magnitude reduction in data size via specialization of I/O libraries associated with …"
  bibAuthors: "Niddodi, Chaitra and Gehani, Ashish and Malik, Tanu and Navas, Jorge A N and Mohan, Sibin"
  Year: 2020
  Month: "June"
  Day: 23
  Date: 20200623
  id: "publication-109"

- title: "Constructing a Cross-Domain Resource Inventory: Key Components and Results of the EarthCube CINERGI Project."
  Authors: "Ilya Zaslavsky, Stephen M Richard, Tanu Malik, Leslie Hsu, Amarnath Gupta, Jeffrey S Grethe, DW Valentine Jr, KA Lehnert, Luis E Bermudez, Ibrahim Burak Ozyurt, Thomas Whitenack, Adam Schachne, and Alice Giliarini"
  Journal: "AGU Fall Meeting Abstracts"
  Volume: "2015"
  Pages: "IN21B-1687"
  Description: "While many geoscience-related repositories and data discovery portals exist, finding information about available resources remains a pervasive problem, especially when searching across multiple domains and catalogs. Inconsistent and incomplete metadata descriptions, disparate access protocols and semantic differences across domains, and troves of unstructured or poorly structured information which is hard to discover and use are major hindrances toward discovery, while metadata compilation and curation remain manual and time-consuming. We report on methodology, main results and lessons learned from an ongoing effort to develop a geoscience-wide catalog of information resources, with consistent metadata descriptions, traceable provenance, and automated metadata enhancement. Developing such a catalog is the central goal of CINERGI (Community Inventory of EarthCube Resources for …"
  bibAuthors: "Zaslavsky, Ilya and Richard, Stephen M R and Malik, Tanu and Hsu, Leslie and Gupta, Amarnath and Grethe, Jeffrey S G and Jr, DW V J and Lehnert, KA and Bermudez, Luis E B and Ozyurt, Ibrahim B O and Whitenack, Thomas and Schachne, Adam and Giliarini, Alice"
  Year: 2015
  Month: "December"
  Date: 20151200
  id: "publication-110"

- title: "A Data Model Supporting Intelligent Search for Materials Research"
  Authors: "Stephen D Stamatis, Balachandra B Krishnamurthy, Amr Shehab, Tanu Malik, Leif Delgass, Steven R Dunlop, and James M Caruthers"
  Journal: "The 2008 Annual Meeting"
  Description: "High-Throughput Experimentation (HTE) enables researchers with the ability to generate massive amounts of data. HTE is typically used to indentify 蘇 ot'material candidates, where the information from the 祖 old'candidates is discarded. However, if experiments are properly designed all data is useful in developing an understanding of the material or process under investigation. In order to gain maximal value from HTE data, the data must be managed in a manner that facilitates knowledge extraction by integrating data from multiple sources, including both lab experiments and computer simulations. Traditional techniques of managing data using nested file folders on local computer network resources are capable of storing the data, but searching data that is stored in this manner is nearly impossible because the data are typically incomplete, have insufficient provenance, are not cataloged correctly and cannot be queried intelligently using domain specific language with complex syntax.
          

           We have developed a general data model as part of the SciAether TM (www. SciAether. org) software system that is capable of serving the data needs of multiple chemistry domains in a flexible and searchable manner. The data model for experimental information distinguishes two classes of materials:(1) an ideal material, which could be a mixture of ideal materials;(2) the actual material in a given batch including all impurities, which is characterized by both its composition and the sequences of 爽 nit operations' used in its synthesis. Materials are involved in synthesis, characterization and performance experiments. In silico experiments are also included in this …"
  bibAuthors: "Stamatis, Stephen D S and Krishnamurthy, Balachandra B K and Shehab, Amr and Malik, Tanu and Delgass, Leif and Dunlop, Steven R D and Caruthers, James M C"
  Year: 2008
  Date: 20080000
  id: "publication-111"

- title: "An invariant framework for conducting reproducible computational science"
  Authors: "Haiyan Meng, Rupa Kommineni, Quan Pham, Robert Gardner, Tanu Malik, and Douglas Thain"
  Journal: "Journal of Computational Science"
  Volume: "9"
  Pages: "137-142"
  Publisher: "Elsevier"
  Description: "Computational reproducibility depends on the ability to not only isolate necessary and sufficient computational artifacts but also to preserve those artifacts for later re-execution. Both isolation and preservation present challenges in large part due to the complexity of existing software and systems as well as the implicit dependencies, resource distribution, and shifting compatibility of systems that result over time—all of which conspire to break the reproducibility of an application. Sandboxing is a technique that has been used extensively in OS environments in order to isolate computational artifacts. Several tools were proposed recently that employ sandboxing as a mechanism to ensure reproducibility. However, none of these tools preserve the sandboxed application for re-distribution to a larger scientific community aspects that are equally crucial for ensuring reproducibility as sandboxing itself. In this paper, we …"
  bibAuthors: "Meng, Haiyan and Kommineni, Rupa and Pham, Quan and Gardner, Robert and Malik, Tanu and Thain, Douglas"
  Year: 2015
  Month: "July"
  Day: 1
  Date: 20150701
  id: "publication-112"

- title: "Liferaft: Data-driven, batch processing for the exploration of scientific databases"
  Authors: "Xiaodan Wang, Randal Burns, and Tanu Malik"
  Journal: "arXiv preprint arXiv:0909.1760"
  Description: "Workloads that comb through vast amounts of data are gaining importance in the sciences. These workloads consist of needle in a haystack queries that are long running and data intensive so that query throughput limits performance. To maximize throughput for data-intensive queries, we put forth LifeRaft: a query processing system that batches queries with overlapping data requirements. Rather than scheduling queries in arrival order, LifeRaft executes queries concurrently against an ordering of the data that maximizes data sharing among queries. This decreases I/O and increases cache utility. However, such batch processing can increase query response time by starving interactive workloads. LifeRaft addresses starvation using techniques inspired by head scheduling in disk drives. Depending upon the workload saturation and queuing times, the system adaptively and incrementally trades-off processing queries in arrival order and data-driven batch processing. Evaluating LifeRaft in the SkyQuery federation of astronomy databases reveals a two-fold improvement in query throughput."
  bibAuthors: "Wang, Xiaodan and Burns, Randal and Malik, Tanu"
  Year: 2009
  Month: "September"
  Day: 9
  Date: 20090909
  id: "publication-113"

- title: "SciInc: A Container Runtime for Incremental Recomputation"
  Authors: "Andrew Youngdahl, Dai-Hai Ton-That, and Tanu Malik"
  Conference: "2019 15th International Conference on eScience (eScience)"
  Pages: "291-300"
  Publisher: "IEEE"
  Description: "The conduct of reproducible science improves when computations are portable and verifiable. A container runtime provides an isolated environment for running computations and thus is useful for porting applications on new machines. Current container engines, such as LXC and Docker, however, do not track provenance, which is essential for verifying computations. In this paper, we present SciInc, a container runtime that tracks the provenance of computations during container creation. We show how container engines can use audited provenance data for efficient container replay. SciInc observes inputs to computations, and, if they change, propagates the changes, re-using partially memoized computations and data that are identical across replay and original run. We chose light-weight data structures for storing the provenance trace to maintain the invariant of shareable and portable container runtime. To …"
  bibAuthors: "Youngdahl, Andrew and Ton-That, Dai-Hai and Malik, Tanu"
  Year: 2019
  Month: "September"
  Day: 24
  Date: 20190924
  id: "publication-114"

- title: "LDI: Learned Distribution Index for Column Stores"
  Authors: "Dai-Hai Ton That, Mohammadsaleh Gharehdaghi, Alexander Rasin, and Tanu Malik"
  Conference: "2021 IEEE International Conference on Big Data (Big Data)"
  Pages: "376-387"
  Publisher: "IEEE"
  Description: "In column stores, which ingest large amounts of data into multiple column groups, query performance deteriorates. Commercial column stores use log-structured merge (LSM) tree on projections to ingest data rapidly. LSM improves ingestion performance, but in column stores the sort-merge phase is I/O-intensive, which slows concurrent queries and reduces overall throughput. In this paper, we aim to reduce the sorting and merging cost that arise when data is ingested in column stores. We present LDI, a learned distribution index for column stores. LDI learns a frequency-based data distribution and constructs a bucket worth of data based on the learned distribution. Filled buckets that conform to the distribution are written out to disk; unfilled buckets are retained to achieve the desired level of sortedness, thus avoiding the expensive sort-merge phase. We present an algorithm to learn and adapt to distributions, and a …"
  bibAuthors: "That, Dai-Hai T T and Gharehdaghi, Mohammadsaleh and Rasin, Alexander and Malik, Tanu"
  Year: 2021
  Month: "December"
  Day: 15
  Date: 20211215
  id: "publication-115"

- title: "Interactive provenance summaries for reproducible science"
  Authors: "Xiang Li, Xiaoyang Xu, and Tanu Malik"
  Conference: "2016 IEEE 12th International Conference on e-Science (e-Science)"
  Pages: "355-360"
  Publisher: "IEEE"
  Description: "Recorded provenance facilitates reproducible science. Provenance metadata can help determine how data were possibly transformed, processed, and derived from original sources. While provenance is crucial for verification and validation, there remains the issue of the granularity - detail at which provenance data must be provided to a user, especially for conducting reproducible science. When data are reproduced successfully the need for detailed provenance is minimal and an essence of the recorded provenance suffices. However, when data are not reproduced correctly users want to quickly drill down into fine-grained provenance to understand causes for failure. In this paper, we describe a drill-up/drill-down method for exploring provenance traces. The drill-up method summarizes the trace by grouping nodes and edges of the trace that have same derivation histories. The method preserves provenance data …"
  bibAuthors: "Li, Xiang and Xu, Xiaoyang and Malik, Tanu"
  Year: 2016
  Month: "October"
  Day: 23
  Date: 20161023
  id: "publication-116"

- title: "Towards a provenance-aware distributed filesystem"
  Authors: "Chen Shou, Dongfang Zhao, Tanu Malik, and Ioan Raicu"
  Journal: "5th Workshop on the Theory and Practice of Provenance (TaPP)"
  Description: "It has become increasingly important to capture and understand the origins and derivation of data (its provenance). A key issue in evaluating the feasibility of data provenance is its performance, overheads, and scalability. This paper presents a provenance-aware distributed filesystem, that offers excellent scalability while retaining the provenance overhead negligible under certain conditions. This work integrated two recent research projects, SPADE (Support for Provenance Auditing in Distributed Environments) and FusionFS (Fusion distributed File System) with simple and efficient communication protocols. The preliminary results on a 32-node cluster show that FusionFS+ SPADE is a promising prototype with negligible provenance overhead and has promise to scale to larger scales as FusionFS has been shown to scale."
  bibAuthors: "Shou, Chen and Zhao, Dongfang and Malik, Tanu and Raicu, Ioan"
  Year: 2013
  Date: 20130000
  id: "publication-117"

- title: "Astronomical Data Query Language: Simple Query Protocol for the Virtual Observatory"
  Authors: "Tanu Malik, Alexander S Szalay, and Martin Hill"
  Description: "The Astronomical Data Query Language (ADQL) is a proposed standard query language for the interoperability of the International Virtual Observatory. The data servers in the International Virtual Observatory could be searched using an ADQL query. The servers would return VOTables as a result of the query."
  bibAuthors: "Malik, Tanu and Szalay, Alexander S S and Hill, Martin"
  id: "publication-118"

- title: "LDV: Light-weight database virtualization"
  Authors: "Quan Pham, Tanu Malik, Boris Glavic, and Ian Foster"
  Conference: "2015 IEEE 31st International Conference on Data Engineering"
  Pages: "1179-1190"
  Publisher: "IEEE"
  Description: "We present a light-weight database virtualization (LDV) system that allows users to share and re-execute applications that operate on a relational database (DB). Previous methods for sharing DB applications, such as companion websites and virtual machine images (VMIs), support neither easy and efficient re-execution nor the sharing of only a relevant DB subset. LDV addresses these issues by monitoring application execution, including DB operations, and using the resulting execution trace to create a lightweight re-executable package. A LDV package includes, in addition to the application, either the DB management system (DBMS) and relevant data or, if the DBMS and/or data cannot be shared, just the application-DBMS communications for replay during re-execution. We introduce a linked DB-operating system provenance model and show how to infer data dependencies based on temporal information …"
  bibAuthors: "Pham, Quan and Malik, Tanu and Glavic, Boris and Foster, Ian"
  Year: 2015
  Month: "April"
  Day: 13
  Date: 20150413
  id: "publication-119"

- title: "Reproducibility Practice in High-Performance Computing: Community Survey Results"
  Authors: "Beth A Plale, Tanu Malik, and Line C Pouchard"
  Journal: "Computing in Science & Engineering"
  Volume: "23"
  Issue: "5"
  Pages: "55-60"
  Publisher: "IEEE"
  Description: "The integrity of science and engineering research is grounded in assumptions of rigor and transparency on the part of those engaging in such research. HPC community effort to strengthen rigor and transparency take the form of reproducibility efforts. In a recent survey of the SC conference community, we collected information about the SC reproducibility initiative activities. We present the survey results in this article. Results show that the reproducibility initiative activities have contributed to higher levels of awareness on the part of SC conference technical program participants, and hint at contributing to greater scientific impact for the published papers of the SC conference series. Stringent point-of-manuscript-submission verification is problematic for reasons we point out, as are inherent difficulties of computational reproducibility in HPC. Future efforts should better decouple the community educational goals from …"
  bibAuthors: "Plale, Beth A P and Malik, Tanu and Pouchard, Line C P"
  Year: 2021
  Month: "September"
  Day: 24
  Date: 20210924
  id: "publication-120"

